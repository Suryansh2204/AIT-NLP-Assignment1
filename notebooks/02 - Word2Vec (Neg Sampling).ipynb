{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec (Negative Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading semcor: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import semcor\n",
    "\n",
    "nltk.download('semcor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce RTX 2080 with Max-Q Design')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semcor.words()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. tokenization\n",
    "corpus = semcor.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. numeralization\n",
    "#find unique words\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "#assign unique integer\n",
    "vocabs = list(set(flatten(corpus))) #all the words we have in the system - <UNK>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create handy mapping between integer and word\n",
    "word2index = {v:idx for idx, v in enumerate(vocabs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs.append('<UNK>')\n",
    "word2index['<UNK>'] = len(vocabs) - 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {v:k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pairs of center word, and outside word\n",
    "\n",
    "def random_batch(batch_size, corpus, window_size=2):\n",
    "\n",
    "    skipgrams = []\n",
    "\n",
    "    #loop each corpus\n",
    "    for doc in corpus:\n",
    "        #look from the 2nd word until second last word\n",
    "        for i in range(window_size, len(doc)-window_size):\n",
    "            #center word\n",
    "            center = word2index[doc[i]]\n",
    "            \n",
    "            #outside words (window size on both sides of the center word)\n",
    "            outside_start =  i - window_size\n",
    "            outside_end =  i + window_size + 1 # +1 because the end index is exclusive\n",
    "\n",
    "            # outside = []\n",
    "            # loop through the outside words, append to the list 'outside'\n",
    "            for j in range(outside_start, outside_end):\n",
    "                if i != j:  # Skip the center word\n",
    "                    outside= word2index[doc[j]]\n",
    "                    skipgrams.append([center, outside])\n",
    "\n",
    "                \n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
    "    \n",
    "    inputs, labels = [], []\n",
    "    for index in random_index:\n",
    "        inputs.append([skipgrams[index][0]])\n",
    "        labels.append([skipgrams[index][1]])\n",
    "        \n",
    "    return np.array(inputs), np.array(labels)\n",
    "            \n",
    "x, y = random_batch(2, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape  #batch_size, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24280],\n",
       "       [26863]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape  #batch_size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Negative Sampling\n",
    "\n",
    "### Unigram distribution\n",
    "\n",
    "$$P(w)=U(w)^{3/4}/Z$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820411"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count\n",
    "from collections import Counter\n",
    "\n",
    "word_count = Counter(flatten(corpus))\n",
    "word_count\n",
    "\n",
    "#get the total number of words\n",
    "num_total_words = sum([c for w, c in word_count.items()])\n",
    "num_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Spectra',\n",
       " 'Result',\n",
       " 'speaks',\n",
       " 'Worth',\n",
       " 'Porgy',\n",
       " 'equate',\n",
       " 'suffered',\n",
       " 'eyeball',\n",
       " 'led',\n",
       " 'spring',\n",
       " 'appealing',\n",
       " 'saucepan',\n",
       " 'industries',\n",
       " 'Andy',\n",
       " 'elevates',\n",
       " 'reverie',\n",
       " 'tendon',\n",
       " 'commemorates',\n",
       " 'Igbo',\n",
       " 'genesis',\n",
       " 'Mist',\n",
       " 'Reub',\n",
       " 'Stetson',\n",
       " 'unmixed',\n",
       " 'fuels',\n",
       " 'd-c',\n",
       " 'qualms',\n",
       " 'electromagnetic',\n",
       " 'nominating',\n",
       " 'Response',\n",
       " 'timers',\n",
       " 'Steinberg',\n",
       " 'begin',\n",
       " 'Clement',\n",
       " 'skips',\n",
       " 'retrieve',\n",
       " 'existing',\n",
       " 'firmer',\n",
       " 'dismay',\n",
       " 'Tsar',\n",
       " 'voted',\n",
       " 'pocketbook',\n",
       " 'Revolutionary',\n",
       " 'awash',\n",
       " 'derrick',\n",
       " 'curdling',\n",
       " 'confronted',\n",
       " 'evocative',\n",
       " 'weatherstrip',\n",
       " 'indexing',\n",
       " 'subcontracting',\n",
       " 'crosses',\n",
       " 'all-purpose',\n",
       " 'reckon',\n",
       " 'anionic',\n",
       " 'delicious',\n",
       " 'Octet',\n",
       " 'Antietam',\n",
       " 'chairs',\n",
       " 'settle',\n",
       " 'Pettersson',\n",
       " 'humane',\n",
       " 'Swallow-Barn',\n",
       " 'outpouring',\n",
       " 'Extensions',\n",
       " 'symmetry',\n",
       " 'Revolution',\n",
       " 'thirty-three',\n",
       " 'Sears',\n",
       " 'Lionel',\n",
       " 'farce',\n",
       " 'give',\n",
       " 'Lockheed',\n",
       " 'Brassbound',\n",
       " 'transience',\n",
       " 'Atomic',\n",
       " 'inevitability',\n",
       " 'hearest',\n",
       " 'discord',\n",
       " 'folk-music',\n",
       " 'Jenks',\n",
       " 'Lot',\n",
       " 'rightness',\n",
       " 'critters',\n",
       " 'laboratory',\n",
       " 'locker',\n",
       " 'acording',\n",
       " 'Gill',\n",
       " 'tall-growing',\n",
       " 'bemoans',\n",
       " 'shield',\n",
       " 'transducer',\n",
       " 'Slough',\n",
       " 'calves',\n",
       " 'despairingly',\n",
       " 'secession',\n",
       " 'Ullman',\n",
       " 'pedimented',\n",
       " 'Glowering',\n",
       " 'second-echelon',\n",
       " 'snake',\n",
       " 'Vermejo',\n",
       " 'acclaims',\n",
       " 'navigate',\n",
       " 'Kings',\n",
       " 'monkeys',\n",
       " 'Somay',\n",
       " 'Appropriations',\n",
       " 'epiphysis',\n",
       " 'teen-ager',\n",
       " 'Beautiful',\n",
       " 'halo',\n",
       " 'Hampshire',\n",
       " '102285000',\n",
       " 'Grapefruit',\n",
       " 'playful',\n",
       " '04.2',\n",
       " 'discoveries',\n",
       " 'Aristotelian',\n",
       " 'antiphonal',\n",
       " 'Native',\n",
       " 'letterman',\n",
       " 'cruising',\n",
       " 'Microscopic',\n",
       " 'originals',\n",
       " 'Retired',\n",
       " 'were',\n",
       " 'Tucson',\n",
       " '1850',\n",
       " 'hostesses',\n",
       " 'malformations',\n",
       " '1921',\n",
       " 'chugging',\n",
       " 'aspen',\n",
       " 'Riggs',\n",
       " 'Aurelius',\n",
       " 'manager',\n",
       " 'Diet',\n",
       " 'floods',\n",
       " 'teamsters',\n",
       " 'Pisces',\n",
       " 'set',\n",
       " 'Seeming',\n",
       " 'strongest',\n",
       " 'Mutants',\n",
       " 'Minnett',\n",
       " 'Afranio',\n",
       " 'asserting',\n",
       " 'abnormal',\n",
       " 'eagerly',\n",
       " 'babbiting',\n",
       " 'whether',\n",
       " 'calumny',\n",
       " 'tending',\n",
       " 'Belmont',\n",
       " 'damed',\n",
       " 'Horton',\n",
       " 'interrupt',\n",
       " 'hedonism',\n",
       " 'Carpenter',\n",
       " 'corniest',\n",
       " 'salamander',\n",
       " 'recognizes',\n",
       " 'Indeed',\n",
       " 'gleaming',\n",
       " 'end',\n",
       " 'Seventeenth',\n",
       " 'undoubtedly',\n",
       " 'Yesterday',\n",
       " 'basso',\n",
       " 'scimitar',\n",
       " 'arteriolosclerosis',\n",
       " 'stone-blind',\n",
       " 'decorum',\n",
       " 'soon',\n",
       " 'Tojos',\n",
       " 'rationalism',\n",
       " 'ciliated',\n",
       " 'two-part',\n",
       " 'dreamin',\n",
       " 'beer-cooling',\n",
       " 'Prix',\n",
       " 'stationmaster',\n",
       " 'censorship',\n",
       " 'Ky.',\n",
       " 'urine',\n",
       " 'idiocies',\n",
       " 'dismayed',\n",
       " 'Triandos',\n",
       " 'bureaucracy',\n",
       " 'Walt',\n",
       " 'week-long',\n",
       " 'headsman',\n",
       " 'fiscal',\n",
       " 'intervals',\n",
       " 'importance',\n",
       " 'haint',\n",
       " 'charge-a-plate',\n",
       " 'resignation',\n",
       " 'corrugated',\n",
       " 'mint',\n",
       " 'regularly',\n",
       " 'Front',\n",
       " 'gliders',\n",
       " 'universally',\n",
       " 'clients',\n",
       " 'posterity',\n",
       " 'propriety',\n",
       " 'Diving',\n",
       " 'fair-looking',\n",
       " 'sluggers',\n",
       " 'dots',\n",
       " 'bulk',\n",
       " 'Gannett',\n",
       " 'rot',\n",
       " 'Pardon',\n",
       " 'healing',\n",
       " 'residential',\n",
       " 'proper',\n",
       " 'checkbook',\n",
       " 'Jap',\n",
       " 'Trumbull',\n",
       " 'ruddy',\n",
       " 'Ironically',\n",
       " 'hard-to-get',\n",
       " 'divider',\n",
       " 'setup',\n",
       " 'disarming',\n",
       " 'castigation',\n",
       " 'Popular',\n",
       " 'aber',\n",
       " 'Natalie',\n",
       " 'Sitting',\n",
       " 'elevator',\n",
       " 'Sunset',\n",
       " 'stolen',\n",
       " 'Charlotte',\n",
       " 'Colorama',\n",
       " 'Hartweger',\n",
       " 'bowed',\n",
       " 'Prison',\n",
       " 'attacked',\n",
       " 'stitched',\n",
       " 'Physicians',\n",
       " 'halftime',\n",
       " 'marriage',\n",
       " 'amongst',\n",
       " 'specialization',\n",
       " 'Platonic',\n",
       " 'linguists',\n",
       " 'self-interest',\n",
       " 'exhaling',\n",
       " 'then',\n",
       " 'deputy',\n",
       " '1846',\n",
       " 'exploitation',\n",
       " 'Policemen',\n",
       " 'submerged',\n",
       " 'Presbyterian',\n",
       " 'Records',\n",
       " 'official',\n",
       " 'beckoned',\n",
       " 'worshiping',\n",
       " 'hugh',\n",
       " 'hens',\n",
       " 'psychologists',\n",
       " 'expedient',\n",
       " 'sarcastic',\n",
       " 'Axis',\n",
       " 'Hemphill',\n",
       " 'speculate',\n",
       " 'natural',\n",
       " '172400',\n",
       " 'regulative',\n",
       " 'instruct',\n",
       " '1911',\n",
       " 'Eighteenth',\n",
       " 'unashamedly',\n",
       " 'hummocks',\n",
       " 'battlefield',\n",
       " 'golly',\n",
       " 'McKenzie',\n",
       " 'opening-day',\n",
       " 'adventurous',\n",
       " 'Hallowell',\n",
       " 'mycology',\n",
       " 'jure',\n",
       " 'unequalled',\n",
       " 'Munich',\n",
       " 'Editor',\n",
       " 'shopkeepers',\n",
       " 'fille',\n",
       " 'Gigenza',\n",
       " 'evidencing',\n",
       " 'Eire',\n",
       " 'millennium',\n",
       " 'articulated',\n",
       " 'gorging',\n",
       " 'unquestionably',\n",
       " 'Behan',\n",
       " 'chemist',\n",
       " 'Following',\n",
       " 'rattler',\n",
       " 'jitters',\n",
       " 'freshly',\n",
       " 'bluster',\n",
       " 'Same',\n",
       " 'Ambushes',\n",
       " 'location',\n",
       " 'directrices',\n",
       " 'other',\n",
       " 'invoke',\n",
       " 'movingly',\n",
       " 'thence',\n",
       " 'burlesque',\n",
       " 'wobbled',\n",
       " 'waning',\n",
       " 'whizzed',\n",
       " 'Gurion',\n",
       " 'detonated',\n",
       " 'Bevel',\n",
       " 'sexton',\n",
       " 'Fitzgerald',\n",
       " 'DeHaviland',\n",
       " 'anti-American',\n",
       " 'Representing',\n",
       " 'allow',\n",
       " 'Royaux',\n",
       " 'rudeness',\n",
       " '02',\n",
       " 'asks',\n",
       " 'aim',\n",
       " 'linoleum',\n",
       " 'Commander-in-Chief',\n",
       " 'lost',\n",
       " '1957',\n",
       " 'gesture',\n",
       " 'trades',\n",
       " 'malaise',\n",
       " 'doghouse',\n",
       " 'Shall',\n",
       " 'overindulged',\n",
       " '8280',\n",
       " 'pantheist',\n",
       " 'Deutsche',\n",
       " 'occluded',\n",
       " 'honeymoon',\n",
       " 'Maynor',\n",
       " 'atrociously',\n",
       " 'tribunals',\n",
       " 'pursed',\n",
       " 'Interstate',\n",
       " 'blossomed',\n",
       " 'echoed',\n",
       " 'sustenance',\n",
       " 'employers',\n",
       " 'slacks',\n",
       " '1769',\n",
       " 'swung',\n",
       " 'graceful',\n",
       " '725',\n",
       " 'supplanting',\n",
       " 'naked',\n",
       " 'nilpotent',\n",
       " 'depart',\n",
       " 'Billy',\n",
       " 'Lorena',\n",
       " 'Beirut',\n",
       " 'double-breasted',\n",
       " 'rosy',\n",
       " 'legally',\n",
       " 'serviceable',\n",
       " 'Lois',\n",
       " 'optional',\n",
       " 'antiquated',\n",
       " 'Length',\n",
       " 'Pohly',\n",
       " 'incarnation',\n",
       " 'forma',\n",
       " 'Placing',\n",
       " 'indirect',\n",
       " 'kamikaze',\n",
       " 'confessed',\n",
       " 'reinforced',\n",
       " 'Sailing',\n",
       " 'pardonable',\n",
       " 'assist',\n",
       " 'Warsaw',\n",
       " 'sheered',\n",
       " 'Chopin',\n",
       " 'Guard',\n",
       " 'ecumenicists',\n",
       " 'Afro-Asian',\n",
       " 'Grabski',\n",
       " 'licked',\n",
       " 'impersonal',\n",
       " 'forswears',\n",
       " 'hunted',\n",
       " 'Nevada',\n",
       " 'classifications',\n",
       " 'Beatrice',\n",
       " 'speech',\n",
       " 'understated',\n",
       " 'Push-Pull',\n",
       " 'coconut',\n",
       " 'hopscotch',\n",
       " 'Dimes',\n",
       " 'Pornsen',\n",
       " 'Sunday',\n",
       " 'ex-fighter',\n",
       " 'centennial',\n",
       " 'scheme',\n",
       " 'Adcock',\n",
       " '97',\n",
       " 'surprises',\n",
       " 'Burnes',\n",
       " 'Knoll',\n",
       " 'inspect',\n",
       " '.028',\n",
       " 'dishonesty',\n",
       " 'corrupts',\n",
       " 'Territories',\n",
       " 'Plunking',\n",
       " 'bearings',\n",
       " 'alight',\n",
       " 'significant',\n",
       " 'precocity',\n",
       " 'Snapped',\n",
       " 'Ruger',\n",
       " 'satirist',\n",
       " 'Morrison',\n",
       " 'Yehudi',\n",
       " 'betrays',\n",
       " 'Honshu',\n",
       " 'forest',\n",
       " 'Catskills',\n",
       " 'Seventeen',\n",
       " 'half-turned',\n",
       " 'Sides',\n",
       " 'scrap',\n",
       " 'layer',\n",
       " 'typewriters',\n",
       " 'Aye-yah-ah-ah',\n",
       " 'penalties',\n",
       " 'De',\n",
       " 'straightaway',\n",
       " 'Passage',\n",
       " 'Wister',\n",
       " 'colon',\n",
       " 'despatched',\n",
       " 'processing',\n",
       " 'Severna',\n",
       " 'See',\n",
       " 'WBAI',\n",
       " 'explosives',\n",
       " 'portfolio',\n",
       " 'fares',\n",
       " 'oats',\n",
       " 'ramification',\n",
       " 'blitzes',\n",
       " 'replacing',\n",
       " 'monitoring',\n",
       " 'Pemberton',\n",
       " 'transversely',\n",
       " 'concessionaire',\n",
       " 'tailgate',\n",
       " 'pickup',\n",
       " 'encephalographic',\n",
       " 'Professionally',\n",
       " 'Daly',\n",
       " 'enacting',\n",
       " 'sledding',\n",
       " 'Citizen',\n",
       " 'undersecretary',\n",
       " 'Lay',\n",
       " 'Rondo',\n",
       " 'awfully',\n",
       " 'cards',\n",
       " 'truths',\n",
       " '11744',\n",
       " 'Dung',\n",
       " 'knotted',\n",
       " 'estranged',\n",
       " 'McLish',\n",
       " 'prohibited',\n",
       " 'mustiness',\n",
       " 'winking',\n",
       " 'vocalic',\n",
       " 'funnier',\n",
       " 'monograph',\n",
       " 'meats',\n",
       " 'Huntingtons',\n",
       " 'urging',\n",
       " 'reclassified',\n",
       " 'conveniently',\n",
       " 'marshalled',\n",
       " 'pre-war',\n",
       " 'resultant',\n",
       " 'Dilys',\n",
       " 'Conference',\n",
       " 'appointee',\n",
       " 'humanity',\n",
       " 'snows',\n",
       " 'Machines',\n",
       " 'Roman',\n",
       " 'self-preservation',\n",
       " 'incalculable',\n",
       " 'exaggerate',\n",
       " 'catechism',\n",
       " 'prose',\n",
       " 'booklet',\n",
       " 'therapeutic',\n",
       " 'redeemed',\n",
       " 'Parti',\n",
       " 'wisely',\n",
       " 'brightest',\n",
       " 'electrotherapist',\n",
       " 'arcus',\n",
       " 'tournaments',\n",
       " 'conjoined',\n",
       " 'prudentially',\n",
       " 'kisses',\n",
       " 'scrutin',\n",
       " 'Elena',\n",
       " 'inversely',\n",
       " 'uprooted',\n",
       " 'commentators',\n",
       " 'yearnings',\n",
       " 'threes',\n",
       " 'Worcestershire',\n",
       " 'Bustard',\n",
       " 'Karol',\n",
       " 'recipient',\n",
       " 'mid-fifties',\n",
       " 'Bartol',\n",
       " 'family-oriented',\n",
       " 'admirers',\n",
       " 'grasp',\n",
       " 'inning',\n",
       " 'bend',\n",
       " 'unendurable',\n",
       " 'facility',\n",
       " 'warmly',\n",
       " 'Thirties',\n",
       " 'self-critical',\n",
       " 'point',\n",
       " 'lui',\n",
       " 'glides',\n",
       " 'identifications',\n",
       " 'impotence',\n",
       " 'hard-to-please',\n",
       " 'bureau',\n",
       " 'Lower',\n",
       " 'civil',\n",
       " 'stone-still',\n",
       " 'Kodyke',\n",
       " 'trigonal',\n",
       " 'obliterating',\n",
       " 'East',\n",
       " 'Platter',\n",
       " 'Considerable',\n",
       " 'hiss',\n",
       " 'birdbath',\n",
       " 'nab',\n",
       " 'passes',\n",
       " 'letting',\n",
       " 'synchronize',\n",
       " 'Rosemary',\n",
       " 'Hunter',\n",
       " 'bhoy',\n",
       " 'broad',\n",
       " 'Jahr',\n",
       " 'mounting',\n",
       " 'yesteryear',\n",
       " 'blinked',\n",
       " 'overeat',\n",
       " 'hedge',\n",
       " 'adjusting',\n",
       " 'grandmothers',\n",
       " 'Community',\n",
       " 'Romano',\n",
       " 'argue',\n",
       " 'Treatment',\n",
       " 'Cares',\n",
       " 'garishness',\n",
       " 'firepower',\n",
       " 'presides',\n",
       " 'foreseeing',\n",
       " 'trichloroacetic',\n",
       " 'cargo',\n",
       " 'bronc',\n",
       " 'Romaniuk',\n",
       " 'Adame',\n",
       " 'good-looking',\n",
       " 'ein',\n",
       " 'doctor',\n",
       " 'Testament',\n",
       " 'Felske',\n",
       " 'nobody',\n",
       " 'lunge',\n",
       " 'Semra',\n",
       " 'planer',\n",
       " 'Directionality',\n",
       " 'shortcuts',\n",
       " 'rough',\n",
       " 'slapping',\n",
       " 'Branch',\n",
       " 'Fleisher',\n",
       " 'Prose',\n",
       " 'eleventh',\n",
       " 'indenture',\n",
       " 'leadership',\n",
       " 'performer',\n",
       " 'Reduced',\n",
       " 'storyline',\n",
       " 'violate',\n",
       " 'Ed',\n",
       " 'rally',\n",
       " 'mentioning',\n",
       " 'Mayer',\n",
       " 'enterprise',\n",
       " 'Security',\n",
       " 'reached',\n",
       " 'monde',\n",
       " 'pathologist',\n",
       " 'Helping',\n",
       " 'Acey',\n",
       " 'didn',\n",
       " 'rotor',\n",
       " 'transitions',\n",
       " 'Reps.',\n",
       " 'flashing',\n",
       " '1886',\n",
       " 'Haqvin',\n",
       " 'Robbery',\n",
       " 'Kleiber',\n",
       " 'Sokol',\n",
       " 'Booby',\n",
       " 'nests',\n",
       " 'arable',\n",
       " 'powder',\n",
       " 'Torah',\n",
       " 'sprays',\n",
       " 'prefaced',\n",
       " 'Rickards',\n",
       " 'detractor',\n",
       " 'interrelations',\n",
       " 'Prohibition',\n",
       " 'confide',\n",
       " 'Athabascan',\n",
       " 'Rig-Veda',\n",
       " 'Wonderland',\n",
       " 'humans',\n",
       " 'Dietetic',\n",
       " 'straighten',\n",
       " 'Satellites',\n",
       " 'investigated',\n",
       " 'painstakingly',\n",
       " 'forty-fifth',\n",
       " 'Drive-in',\n",
       " 'stretching',\n",
       " 'embankment',\n",
       " 'protests',\n",
       " 'grammar',\n",
       " 'transformation',\n",
       " 'Weider',\n",
       " 'miscalculated',\n",
       " 'adorn',\n",
       " 'Calmer',\n",
       " 'yeah',\n",
       " 'foreboding',\n",
       " 'Colt',\n",
       " 'Quakeress',\n",
       " 'Cinemactor',\n",
       " 'Comique',\n",
       " 'convicted',\n",
       " 'detachable',\n",
       " 'Auxiliaries',\n",
       " 'vermilion',\n",
       " 'involve',\n",
       " 'drifts',\n",
       " 'overexcited',\n",
       " 'Pompadour',\n",
       " 'rhythmic',\n",
       " 'affectionate',\n",
       " 'nip',\n",
       " 'desiring',\n",
       " 'Farnese',\n",
       " 'Bruhn',\n",
       " 'slights',\n",
       " 'Stephanie',\n",
       " 'insulted',\n",
       " 'Rameau',\n",
       " 'Cleanth',\n",
       " 'out-reaching',\n",
       " 'Tolley',\n",
       " 'Thay',\n",
       " 'reserpine',\n",
       " 'pulp',\n",
       " 'names',\n",
       " 'Simplex',\n",
       " 'landslide',\n",
       " 'souvenirs',\n",
       " 'cuisine',\n",
       " 'uptown',\n",
       " 'beginners',\n",
       " 'Packard',\n",
       " 'printing',\n",
       " 'expands',\n",
       " 'terry',\n",
       " 'discrepancy',\n",
       " 'consequences',\n",
       " 'migrant',\n",
       " 'recoil',\n",
       " 'war',\n",
       " 'nailed',\n",
       " 'locations',\n",
       " 'shin',\n",
       " 'stirring',\n",
       " 'Goodwin',\n",
       " 'proclaiming',\n",
       " 'rancor',\n",
       " 'picturing',\n",
       " 'accordion',\n",
       " 'ventilated',\n",
       " 'blandly',\n",
       " 'resent',\n",
       " 'occipital',\n",
       " 'knuckles',\n",
       " 'story',\n",
       " 'reddish',\n",
       " 'outdrew',\n",
       " 'charging',\n",
       " 'consideration',\n",
       " 'Dimensions',\n",
       " 'inglorious',\n",
       " 'vocals',\n",
       " 'SS.',\n",
       " 'Ziegfeld',\n",
       " 'crush',\n",
       " 'draining',\n",
       " 'output',\n",
       " 'LSO',\n",
       " 'Pinscher',\n",
       " 'arch',\n",
       " 'O.K.',\n",
       " 'Gennaro',\n",
       " 'exacerbation',\n",
       " 'extended',\n",
       " 'munching',\n",
       " 'forsaken',\n",
       " 'bureaucratic',\n",
       " 'toffee',\n",
       " 'Doubtful',\n",
       " 'sobbingly',\n",
       " 'ABO',\n",
       " 'decorating',\n",
       " 'mouthed',\n",
       " 'boxcar',\n",
       " 'circa',\n",
       " 'Astor',\n",
       " 'Breakfast',\n",
       " 'falling',\n",
       " 'path',\n",
       " 'dental',\n",
       " 'gluttons',\n",
       " 'stoop',\n",
       " 'strenuously',\n",
       " 'quaint',\n",
       " 'enough',\n",
       " 'Soviet',\n",
       " 'Frans',\n",
       " 'echo',\n",
       " 'creepy',\n",
       " 'Love',\n",
       " 'recriminations',\n",
       " '320',\n",
       " 'maneuverability',\n",
       " 'Skill',\n",
       " 'regulation',\n",
       " 'Hatfield',\n",
       " 'lubrication',\n",
       " 'Tougas',\n",
       " 'milk',\n",
       " 'literatures',\n",
       " 'Crosson',\n",
       " 'Province',\n",
       " 'flame',\n",
       " 'remanded',\n",
       " 'melodies',\n",
       " 'Promoters',\n",
       " 'readjust',\n",
       " 'Uh',\n",
       " 'Someone',\n",
       " 'unawareness',\n",
       " 'mystics',\n",
       " 'blanket',\n",
       " 'Greyhound',\n",
       " 'Sullam',\n",
       " 'pervaded',\n",
       " 'participated',\n",
       " 'addle-brained',\n",
       " 'announcement',\n",
       " 'Richmond-Petersburg',\n",
       " 'Paray',\n",
       " 'crying',\n",
       " 'Wisman',\n",
       " 'Sussex',\n",
       " '11',\n",
       " 'foil',\n",
       " 'specialize',\n",
       " 'engender',\n",
       " 'democracy',\n",
       " 'Mecholyl',\n",
       " 'Butlers',\n",
       " 'rarity',\n",
       " 'savory',\n",
       " 'redefinition',\n",
       " 'Blend',\n",
       " 'whereof',\n",
       " 'plummeting',\n",
       " 'unfriendly',\n",
       " 'Lippman',\n",
       " 'Court-packing',\n",
       " 'chamber',\n",
       " 'defiantly',\n",
       " 'Distally',\n",
       " 'half-heartedly',\n",
       " 'unilaterally',\n",
       " 'corral',\n",
       " 'dodge',\n",
       " 'fine-looking',\n",
       " 'subfigures',\n",
       " 'Buaford',\n",
       " 'detract',\n",
       " 'Co-operative',\n",
       " 'inside',\n",
       " 'one-story',\n",
       " 'Jacinto',\n",
       " 'Rachel',\n",
       " 'aspect',\n",
       " 'Caracas',\n",
       " 'verses',\n",
       " 'Brothers',\n",
       " 'decimal',\n",
       " 'beachhead',\n",
       " 'Landis',\n",
       " 'coincide',\n",
       " 'headroom',\n",
       " 'standing',\n",
       " 'phthalate',\n",
       " 'hells',\n",
       " 'prevision',\n",
       " 'consuming',\n",
       " 'vintage',\n",
       " 'Centredale',\n",
       " 'non-profit',\n",
       " 'forefathers',\n",
       " 'twenty-three',\n",
       " 'Doe',\n",
       " 'Subgroups',\n",
       " 'princes',\n",
       " 'cowboy',\n",
       " 'ill-prepared',\n",
       " 'done',\n",
       " 'Elected',\n",
       " 'punctually',\n",
       " 'siren',\n",
       " 'whiskered',\n",
       " 'disjointed',\n",
       " 'effluents',\n",
       " 'butt',\n",
       " 'lever-action',\n",
       " '19th',\n",
       " 'Alden',\n",
       " 'provokes',\n",
       " 'poets',\n",
       " 'inspire',\n",
       " 'kerosene',\n",
       " 'vibrato',\n",
       " '0.7',\n",
       " 'silver',\n",
       " 'undergirding',\n",
       " 'mis-reading',\n",
       " 'passages',\n",
       " 'breakables',\n",
       " 'gallstone',\n",
       " 'practiced',\n",
       " 'buss',\n",
       " 'pedestrian',\n",
       " 'idiomatic',\n",
       " 'disapproves',\n",
       " 'Forever',\n",
       " 'Thornburg',\n",
       " 'quadrillion',\n",
       " 'hog',\n",
       " 'Internal',\n",
       " 'cracking',\n",
       " 'accord',\n",
       " 'Windsor',\n",
       " 'fill',\n",
       " 'student',\n",
       " 'strong-made',\n",
       " 'occur',\n",
       " 'disappointing',\n",
       " 'mushrooming',\n",
       " 'Poetry',\n",
       " 'sportsmen',\n",
       " 'drowsed',\n",
       " 'undressing',\n",
       " 'spill',\n",
       " 'triangular',\n",
       " 'Melcher',\n",
       " 'group',\n",
       " 'adorable',\n",
       " 'workings',\n",
       " 'swiftness',\n",
       " 'obsequious',\n",
       " 'Cotter',\n",
       " 'spurring',\n",
       " 'mark',\n",
       " 'flaunting',\n",
       " 'outline',\n",
       " 'Sickness',\n",
       " 'demonstrators',\n",
       " 'Shabbat',\n",
       " 'Superior',\n",
       " 'remotely',\n",
       " 'retire',\n",
       " 'downtown',\n",
       " 'measured',\n",
       " 'Tchaikovsky',\n",
       " 'realigning',\n",
       " 'take',\n",
       " 'integrated',\n",
       " '2.5',\n",
       " 'hatted',\n",
       " 'Rusk',\n",
       " 'Suspicion',\n",
       " 'Whether',\n",
       " 'respiratory',\n",
       " 'bottled',\n",
       " 'glottochronological',\n",
       " 'mortality',\n",
       " 'eliminations',\n",
       " 'usage',\n",
       " 'retirements',\n",
       " 'squinting',\n",
       " 'pike',\n",
       " 'dining-room',\n",
       " 'heathenish',\n",
       " 'swaggering',\n",
       " 'co-operating',\n",
       " 'Delaware',\n",
       " 'eliminate',\n",
       " 'Bashir',\n",
       " 'beguiling',\n",
       " 'septic',\n",
       " 'haughtily',\n",
       " 'Masons',\n",
       " 'anti-intellectual',\n",
       " 'S-s-sahjunt',\n",
       " 'outfielders',\n",
       " 'millennia',\n",
       " 'Ambrose',\n",
       " 'bar',\n",
       " 'motive',\n",
       " 'Co.',\n",
       " 'extraterrestrial',\n",
       " 'bother',\n",
       " 'insulated',\n",
       " 'Admiralty',\n",
       " 'Amos',\n",
       " 'Korneyev',\n",
       " 'brink',\n",
       " 'gloomily',\n",
       " 'Mexico',\n",
       " 'Pharmical',\n",
       " 'unpleasantness',\n",
       " 'Assessors',\n",
       " 'shovels',\n",
       " 'intuitively',\n",
       " 'poor',\n",
       " 'Shreveport',\n",
       " 'fanciful',\n",
       " 'kidney',\n",
       " 'item',\n",
       " 'Looky',\n",
       " 'Dog',\n",
       " 'cures',\n",
       " 'Phone',\n",
       " 'blue',\n",
       " 'postures',\n",
       " 'pithy',\n",
       " 'grandparents',\n",
       " 'involution',\n",
       " 'bomb-proof',\n",
       " 'Camden',\n",
       " 'burrowed',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(w)=U(w)^{3/4}/Z$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'the': 111,\n",
       "         ',': 104,\n",
       "         '.': 93,\n",
       "         'of': 72,\n",
       "         'and': 60,\n",
       "         'to': 56,\n",
       "         'a': 50,\n",
       "         'in': 46,\n",
       "         'that': 28,\n",
       "         'is': 28,\n",
       "         'was': 27,\n",
       "         '``': 25,\n",
       "         'for': 25,\n",
       "         \"''\": 25,\n",
       "         'it': 21,\n",
       "         'with': 21,\n",
       "         'The': 21,\n",
       "         'as': 20,\n",
       "         'be': 20,\n",
       "         'he': 20,\n",
       "         'on': 20,\n",
       "         'his': 19,\n",
       "         \"'s\": 18,\n",
       "         'I': 16,\n",
       "         'had': 16,\n",
       "         'by': 16,\n",
       "         'at': 16,\n",
       "         'are': 15,\n",
       "         'not': 15,\n",
       "         'from': 14,\n",
       "         'this': 14,\n",
       "         'or': 14,\n",
       "         '-': 14,\n",
       "         'an': 13,\n",
       "         'have': 13,\n",
       "         'were': 12,\n",
       "         'which': 12,\n",
       "         'they': 11,\n",
       "         'but': 11,\n",
       "         'He': 11,\n",
       "         'one': 11,\n",
       "         'you': 11,\n",
       "         'would': 11,\n",
       "         ';': 10,\n",
       "         'her': 10,\n",
       "         'has': 10,\n",
       "         'all': 10,\n",
       "         'their': 10,\n",
       "         'him': 9,\n",
       "         'will': 9,\n",
       "         'It': 9,\n",
       "         '?': 9,\n",
       "         'been': 9,\n",
       "         'can': 8,\n",
       "         '(': 8,\n",
       "         'out': 8,\n",
       "         'said': 8,\n",
       "         ':': 8,\n",
       "         'we': 8,\n",
       "         'there': 8,\n",
       "         ')': 8,\n",
       "         'up': 8,\n",
       "         'who': 8,\n",
       "         'she': 8,\n",
       "         \"n't\": 8,\n",
       "         'more': 8,\n",
       "         'other': 7,\n",
       "         'into': 7,\n",
       "         'no': 7,\n",
       "         'so': 7,\n",
       "         'could': 7,\n",
       "         'than': 7,\n",
       "         '*': 7,\n",
       "         'In': 7,\n",
       "         'them': 7,\n",
       "         'its': 7,\n",
       "         'do': 7,\n",
       "         'only': 7,\n",
       "         'about': 7,\n",
       "         'when': 7,\n",
       "         'time': 6,\n",
       "         'some': 6,\n",
       "         'any': 6,\n",
       "         'may': 6,\n",
       "         'But': 6,\n",
       "         'what': 6,\n",
       "         'two': 6,\n",
       "         'if': 6,\n",
       "         'did': 6,\n",
       "         'A': 6,\n",
       "         'then': 5,\n",
       "         'new': 5,\n",
       "         'now': 5,\n",
       "         'This': 5,\n",
       "         'these': 5,\n",
       "         'such': 5,\n",
       "         'our': 5,\n",
       "         'first': 5,\n",
       "         'also': 5,\n",
       "         'made': 5,\n",
       "         'like': 5,\n",
       "         'must': 5,\n",
       "         \"'\": 5,\n",
       "         'my': 5,\n",
       "         'most': 5,\n",
       "         'over': 5,\n",
       "         'man': 5,\n",
       "         'If': 4,\n",
       "         'too': 4,\n",
       "         'We': 4,\n",
       "         'after': 4,\n",
       "         'And': 4,\n",
       "         'people': 4,\n",
       "         'very': 4,\n",
       "         'She': 4,\n",
       "         'through': 4,\n",
       "         'those': 4,\n",
       "         '!': 4,\n",
       "         'year': 4,\n",
       "         'much': 4,\n",
       "         'even': 4,\n",
       "         'before': 4,\n",
       "         'where': 4,\n",
       "         'me': 4,\n",
       "         'They': 4,\n",
       "         'many': 4,\n",
       "         'down': 4,\n",
       "         'little': 4,\n",
       "         'long': 4,\n",
       "         'back': 4,\n",
       "         'f': 4,\n",
       "         'each': 4,\n",
       "         'make': 4,\n",
       "         'because': 4,\n",
       "         'years': 4,\n",
       "         'good': 4,\n",
       "         'just': 4,\n",
       "         'way': 4,\n",
       "         'There': 4,\n",
       "         'your': 4,\n",
       "         'should': 4,\n",
       "         'Mr.': 4,\n",
       "         'take': 3,\n",
       "         'off': 3,\n",
       "         'last': 3,\n",
       "         'few': 3,\n",
       "         'does': 3,\n",
       "         'right': 3,\n",
       "         'without': 3,\n",
       "         'world': 3,\n",
       "         'never': 3,\n",
       "         'old': 3,\n",
       "         '2': 3,\n",
       "         'When': 3,\n",
       "         'As': 3,\n",
       "         '$': 3,\n",
       "         'What': 3,\n",
       "         'found': 3,\n",
       "         'place': 3,\n",
       "         'while': 3,\n",
       "         'against': 3,\n",
       "         'around': 3,\n",
       "         'three': 3,\n",
       "         'home': 3,\n",
       "         'men': 3,\n",
       "         'again': 3,\n",
       "         '1': 3,\n",
       "         'how': 3,\n",
       "         'well': 3,\n",
       "         'here': 3,\n",
       "         'For': 3,\n",
       "         'small': 3,\n",
       "         'go': 3,\n",
       "         'come': 3,\n",
       "         'work': 3,\n",
       "         'us': 3,\n",
       "         'might': 3,\n",
       "         'both': 3,\n",
       "         'another': 3,\n",
       "         'see': 3,\n",
       "         'American': 3,\n",
       "         'own': 3,\n",
       "         'great': 3,\n",
       "         'His': 3,\n",
       "         'You': 3,\n",
       "         'himself': 3,\n",
       "         'New': 3,\n",
       "         'used': 3,\n",
       "         'life': 3,\n",
       "         'use': 3,\n",
       "         'under': 3,\n",
       "         'same': 3,\n",
       "         'came': 3,\n",
       "         'know': 3,\n",
       "         'between': 3,\n",
       "         'state': 3,\n",
       "         'get': 3,\n",
       "         'being': 3,\n",
       "         'Mrs.': 3,\n",
       "         'still': 3,\n",
       "         'day': 3,\n",
       "         'give': 2,\n",
       "         'set': 2,\n",
       "         'end': 2,\n",
       "         'point': 2,\n",
       "         'war': 2,\n",
       "         'enough': 2,\n",
       "         'done': 2,\n",
       "         'group': 2,\n",
       "         'week': 2,\n",
       "         'part': 2,\n",
       "         'along': 2,\n",
       "         \"'ll\": 2,\n",
       "         'asked': 2,\n",
       "         'since': 2,\n",
       "         'States': 2,\n",
       "         'large': 2,\n",
       "         'area': 2,\n",
       "         'At': 2,\n",
       "         'best': 2,\n",
       "         'help': 2,\n",
       "         'feet': 2,\n",
       "         'second': 2,\n",
       "         'head': 2,\n",
       "         'once': 2,\n",
       "         'today': 2,\n",
       "         'left': 2,\n",
       "         'certain': 2,\n",
       "         'whole': 2,\n",
       "         'government': 2,\n",
       "         'water': 2,\n",
       "         'nothing': 2,\n",
       "         'These': 2,\n",
       "         'interest': 2,\n",
       "         'away': 2,\n",
       "         'looked': 2,\n",
       "         'half': 2,\n",
       "         'less': 2,\n",
       "         'York': 2,\n",
       "         'early': 2,\n",
       "         'four': 2,\n",
       "         'went': 2,\n",
       "         'far': 2,\n",
       "         'That': 2,\n",
       "         'per': 2,\n",
       "         'rather': 2,\n",
       "         'open': 2,\n",
       "         \"'re\": 2,\n",
       "         'God': 2,\n",
       "         'public': 2,\n",
       "         'every': 2,\n",
       "         'took': 2,\n",
       "         'local': 2,\n",
       "         '3': 2,\n",
       "         'upon': 2,\n",
       "         'State': 2,\n",
       "         'different': 2,\n",
       "         'thought': 2,\n",
       "         'big': 2,\n",
       "         'order': 2,\n",
       "         'knew': 2,\n",
       "         'business': 2,\n",
       "         'United': 2,\n",
       "         'itself': 2,\n",
       "         'eyes': 2,\n",
       "         'things': 2,\n",
       "         'young': 2,\n",
       "         'better': 2,\n",
       "         'called': 2,\n",
       "         'side': 2,\n",
       "         'think': 2,\n",
       "         'children': 2,\n",
       "         'began': 2,\n",
       "         'light': 2,\n",
       "         'almost': 2,\n",
       "         'going': 2,\n",
       "         'possible': 2,\n",
       "         'ever': 2,\n",
       "         'form': 2,\n",
       "         'want': 2,\n",
       "         'always': 2,\n",
       "         'face': 2,\n",
       "         'room': 2,\n",
       "         'important': 2,\n",
       "         'several': 2,\n",
       "         'within': 2,\n",
       "         'until': 2,\n",
       "         'system': 2,\n",
       "         'U.': 2,\n",
       "         'told': 2,\n",
       "         'members': 2,\n",
       "         'least': 2,\n",
       "         'during': 2,\n",
       "         'need': 2,\n",
       "         'become': 2,\n",
       "         'President': 2,\n",
       "         'To': 2,\n",
       "         'social': 2,\n",
       "         'next': 2,\n",
       "         'school': 2,\n",
       "         'toward': 2,\n",
       "         'case': 2,\n",
       "         'put': 2,\n",
       "         'high': 2,\n",
       "         'show': 2,\n",
       "         'though': 2,\n",
       "         'number': 2,\n",
       "         'family': 2,\n",
       "         'John': 2,\n",
       "         'among': 2,\n",
       "         \"'d\": 2,\n",
       "         'turned': 2,\n",
       "         'later': 2,\n",
       "         'saw': 2,\n",
       "         'Then': 2,\n",
       "         'power': 2,\n",
       "         'let': 2,\n",
       "         'seemed': 2,\n",
       "         'city': 2,\n",
       "         'given': 2,\n",
       "         'problem': 2,\n",
       "         'night': 2,\n",
       "         'sense': 2,\n",
       "         'course': 2,\n",
       "         'house': 2,\n",
       "         'look': 2,\n",
       "         'thing': 2,\n",
       "         'days': 2,\n",
       "         'No': 2,\n",
       "         'hand': 2,\n",
       "         'however': 2,\n",
       "         'find': 2,\n",
       "         'S.': 2,\n",
       "         'felt': 2,\n",
       "         'fact': 2,\n",
       "         'general': 2,\n",
       "         'say': 2,\n",
       "         'One': 2,\n",
       "         'country': 2,\n",
       "         'program': 2,\n",
       "         'got': 2,\n",
       "         'present': 2,\n",
       "         'something': 2,\n",
       "         'On': 2,\n",
       "         'often': 2,\n",
       "         'door': 2,\n",
       "         'led': 1,\n",
       "         'spring': 1,\n",
       "         'whether': 1,\n",
       "         'soon': 1,\n",
       "         'fiscal': 1,\n",
       "         'natural': 1,\n",
       "         'lost': 1,\n",
       "         'Sunday': 1,\n",
       "         'East': 1,\n",
       "         'reached': 1,\n",
       "         'story': 1,\n",
       "         'Soviet': 1,\n",
       "         'inside': 1,\n",
       "         'bring': 1,\n",
       "         'similar': 1,\n",
       "         'third': 1,\n",
       "         '20': 1,\n",
       "         'increased': 1,\n",
       "         'direct': 1,\n",
       "         'short': 1,\n",
       "         'past': 1,\n",
       "         'mean': 1,\n",
       "         '/': 1,\n",
       "         'church': 1,\n",
       "         'service': 1,\n",
       "         'Yet': 1,\n",
       "         'particular': 1,\n",
       "         'board': 1,\n",
       "         'meet': 1,\n",
       "         'actually': 1,\n",
       "         'Christian': 1,\n",
       "         'filled': 1,\n",
       "         'record': 1,\n",
       "         'considered': 1,\n",
       "         'six': 1,\n",
       "         'issue': 1,\n",
       "         'keep': 1,\n",
       "         'five': 1,\n",
       "         'known': 1,\n",
       "         'J.': 1,\n",
       "         'tried': 1,\n",
       "         'quality': 1,\n",
       "         'college': 1,\n",
       "         'greater': 1,\n",
       "         'national': 1,\n",
       "         'father': 1,\n",
       "         'theory': 1,\n",
       "         'property': 1,\n",
       "         'held': 1,\n",
       "         'persons': 1,\n",
       "         'whose': 1,\n",
       "         'history': 1,\n",
       "         'hall': 1,\n",
       "         'feed': 1,\n",
       "         'lay': 1,\n",
       "         'An': 1,\n",
       "         'James': 1,\n",
       "         'religious': 1,\n",
       "         'larger': 1,\n",
       "         'late': 1,\n",
       "         'tax': 1,\n",
       "         'added': 1,\n",
       "         'hour': 1,\n",
       "         'officer': 1,\n",
       "         'sure': 1,\n",
       "         'dark': 1,\n",
       "         'covered': 1,\n",
       "         'report': 1,\n",
       "         'move': 1,\n",
       "         'labor': 1,\n",
       "         'English': 1,\n",
       "         'happened': 1,\n",
       "         'evidence': 1,\n",
       "         'statement': 1,\n",
       "         'quite': 1,\n",
       "         'University': 1,\n",
       "         'boy': 1,\n",
       "         'chance': 1,\n",
       "         'problems': 1,\n",
       "         'act': 1,\n",
       "         'word': 1,\n",
       "         'William': 1,\n",
       "         'Here': 1,\n",
       "         'music': 1,\n",
       "         'attention': 1,\n",
       "         'earlier': 1,\n",
       "         'Secretary': 1,\n",
       "         'ran': 1,\n",
       "         'although': 1,\n",
       "         'closed': 1,\n",
       "         'picture': 1,\n",
       "         'higher': 1,\n",
       "         'aid': 1,\n",
       "         'cut': 1,\n",
       "         'line': 1,\n",
       "         'former': 1,\n",
       "         'field': 1,\n",
       "         'strong': 1,\n",
       "         'Why': 1,\n",
       "         'became': 1,\n",
       "         'position': 1,\n",
       "         'Let': 1,\n",
       "         'lead': 1,\n",
       "         'sales': 1,\n",
       "         'appeared': 1,\n",
       "         'friends': 1,\n",
       "         'heart': 1,\n",
       "         'believe': 1,\n",
       "         'Southern': 1,\n",
       "         'usually': 1,\n",
       "         'already': 1,\n",
       "         'Church': 1,\n",
       "         'decided': 1,\n",
       "         'reaction': 1,\n",
       "         'strength': 1,\n",
       "         'color': 1,\n",
       "         'recently': 1,\n",
       "         'expected': 1,\n",
       "         'education': 1,\n",
       "         'indicated': 1,\n",
       "         'finally': 1,\n",
       "         'true': 1,\n",
       "         'getting': 1,\n",
       "         'effective': 1,\n",
       "         '1958': 1,\n",
       "         'hundred': 1,\n",
       "         'corner': 1,\n",
       "         'especially': 1,\n",
       "         'human': 1,\n",
       "         'start': 1,\n",
       "         'means': 1,\n",
       "         'son': 1,\n",
       "         'says': 1,\n",
       "         'areas': 1,\n",
       "         'answer': 1,\n",
       "         'stood': 1,\n",
       "         'floor': 1,\n",
       "         'doing': 1,\n",
       "         'City': 1,\n",
       "         'sort': 1,\n",
       "         'Kennedy': 1,\n",
       "         'numbers': 1,\n",
       "         'coming': 1,\n",
       "         'May': 1,\n",
       "         'forms': 1,\n",
       "         'front': 1,\n",
       "         'single': 1,\n",
       "         'programs': 1,\n",
       "         'Each': 1,\n",
       "         'information': 1,\n",
       "         'low': 1,\n",
       "         'policy': 1,\n",
       "         'showed': 1,\n",
       "         'opened': 1,\n",
       "         'below': 1,\n",
       "         'anyone': 1,\n",
       "         'result': 1,\n",
       "         'available': 1,\n",
       "         'support': 1,\n",
       "         'series': 1,\n",
       "         'South': 1,\n",
       "         'North': 1,\n",
       "         'addition': 1,\n",
       "         'House': 1,\n",
       "         'National': 1,\n",
       "         'future': 1,\n",
       "         'followed': 1,\n",
       "         '8': 1,\n",
       "         'range': 1,\n",
       "         'fall': 1,\n",
       "         'cent': 1,\n",
       "         'gives': 1,\n",
       "         'full': 1,\n",
       "         'peace': 1,\n",
       "         'nearly': 1,\n",
       "         'except': 1,\n",
       "         'paid': 1,\n",
       "         'horse': 1,\n",
       "         '7': 1,\n",
       "         'concerned': 1,\n",
       "         'building': 1,\n",
       "         'trouble': 1,\n",
       "         \"'ve\": 1,\n",
       "         'hear': 1,\n",
       "         'certainly': 1,\n",
       "         'nation': 1,\n",
       "         'points': 1,\n",
       "         'piece': 1,\n",
       "         'run': 1,\n",
       "         'C': 1,\n",
       "         'eye': 1,\n",
       "         'including': 1,\n",
       "         'morning': 1,\n",
       "         'Her': 1,\n",
       "         'others': 1,\n",
       "         'obtained': 1,\n",
       "         'community': 1,\n",
       "         'Federal': 1,\n",
       "         'bed': 1,\n",
       "         'pay': 1,\n",
       "         'deal': 1,\n",
       "         'How': 1,\n",
       "         'call': 1,\n",
       "         'working': 1,\n",
       "         'serious': 1,\n",
       "         'common': 1,\n",
       "         'cases': 1,\n",
       "         'pressure': 1,\n",
       "         'walked': 1,\n",
       "         'amount': 1,\n",
       "         'earth': 1,\n",
       "         'class': 1,\n",
       "         \"'m\": 1,\n",
       "         '**f': 1,\n",
       "         'services': 1,\n",
       "         'mind': 1,\n",
       "         'lines': 1,\n",
       "         'clear': 1,\n",
       "         'car': 1,\n",
       "         'subject': 1,\n",
       "         'else': 1,\n",
       "         'placed': 1,\n",
       "         'design': 1,\n",
       "         'running': 1,\n",
       "         'General': 1,\n",
       "         'everything': 1,\n",
       "         'basic': 1,\n",
       "         'behind': 1,\n",
       "         'schools': 1,\n",
       "         'girl': 1,\n",
       "         'size': 1,\n",
       "         'outside': 1,\n",
       "         'member': 1,\n",
       "         'process': 1,\n",
       "         'action': 1,\n",
       "         'nor': 1,\n",
       "         'Dr.': 1,\n",
       "         'Do': 1,\n",
       "         'beginning': 1,\n",
       "         'seen': 1,\n",
       "         'list': 1,\n",
       "         'money': 1,\n",
       "         'My': 1,\n",
       "         'land': 1,\n",
       "         'industry': 1,\n",
       "         'complete': 1,\n",
       "         'shown': 1,\n",
       "         'longer': 1,\n",
       "         'West': 1,\n",
       "         'C.': 1,\n",
       "         'space': 1,\n",
       "         'black': 1,\n",
       "         'top': 1,\n",
       "         'stress': 1,\n",
       "         'completely': 1,\n",
       "         'thus': 1,\n",
       "         'fire': 1,\n",
       "         'themselves': 1,\n",
       "         'square': 1,\n",
       "         'road': 1,\n",
       "         'started': 1,\n",
       "         'hope': 1,\n",
       "         'miles': 1,\n",
       "         'plane': 1,\n",
       "         'rate': 1,\n",
       "         'change': 1,\n",
       "         'company': 1,\n",
       "         'words': 1,\n",
       "         'movement': 1,\n",
       "         'passed': 1,\n",
       "         'across': 1,\n",
       "         'party': 1,\n",
       "         'entire': 1,\n",
       "         'minutes': 1,\n",
       "         '100': 1,\n",
       "         'Well': 1,\n",
       "         'needs': 1,\n",
       "         'modern': 1,\n",
       "         'yet': 1,\n",
       "         'further': 1,\n",
       "         'direction': 1,\n",
       "         'section': 1,\n",
       "         'th': 1,\n",
       "         'white': 1,\n",
       "         'material': 1,\n",
       "         'having': 1,\n",
       "         'spirit': 1,\n",
       "         'perhaps': 1,\n",
       "         'summer': 1,\n",
       "         'read': 1,\n",
       "         'manner': 1,\n",
       "         'heard': 1,\n",
       "         'body': 1,\n",
       "         'England': 1,\n",
       "         'physical': 1,\n",
       "         'latter': 1,\n",
       "         'near': 1,\n",
       "         'planning': 1,\n",
       "         'person': 1,\n",
       "         'making': 1,\n",
       "         'evening': 1,\n",
       "         'sound': 1,\n",
       "         'hold': 1,\n",
       "         'daily': 1,\n",
       "         '10': 1,\n",
       "         'economic': 1,\n",
       "         'average': 1,\n",
       "         'able': 1,\n",
       "         'reason': 1,\n",
       "         'training': 1,\n",
       "         'either': 1,\n",
       "         '%': 1,\n",
       "         'dead': 1,\n",
       "         'developed': 1,\n",
       "         'sent': 1,\n",
       "         'tell': 1,\n",
       "         'carried': 1,\n",
       "         'why': 1,\n",
       "         'couple': 1,\n",
       "         'Some': 1,\n",
       "         'cannot': 1,\n",
       "         'won': 1,\n",
       "         'death': 1,\n",
       "         'real': 1,\n",
       "         'farm': 1,\n",
       "         'results': 1,\n",
       "         'works': 1,\n",
       "         'ten': 1,\n",
       "         'art': 1,\n",
       "         'terms': 1,\n",
       "         'times': 1,\n",
       "         'wrong': 1,\n",
       "         'really': 1,\n",
       "         'cold': 1,\n",
       "         'difference': 1,\n",
       "         'limited': 1,\n",
       "         'growing': 1,\n",
       "         'role': 1,\n",
       "         'Rhode': 1,\n",
       "         'woman': 1,\n",
       "         'normal': 1,\n",
       "         'street': 1,\n",
       "         'values': 1,\n",
       "         'living': 1,\n",
       "         'wife': 1,\n",
       "         'political': 1,\n",
       "         'looking': 1,\n",
       "         'following': 1,\n",
       "         'fear': 1,\n",
       "         '1960': 1,\n",
       "         'ready': 1,\n",
       "         'involved': 1,\n",
       "         'herself': 1,\n",
       "         'ask': 1,\n",
       "         'am': 1,\n",
       "         'book': 1,\n",
       "         '30': 1,\n",
       "         'Mike': 1,\n",
       "         'lot': 1,\n",
       "         'By': 1,\n",
       "         'stock': 1,\n",
       "         'George': 1,\n",
       "         'seems': 1,\n",
       "         'recent': 1,\n",
       "         'nuclear': 1,\n",
       "         'reading': 1,\n",
       "         'together': 1,\n",
       "         'Communist': 1,\n",
       "         'office': 1,\n",
       "         'type': 1,\n",
       "         'hot': 1,\n",
       "         'playing': 1,\n",
       "         'taken': 1,\n",
       "         'With': 1,\n",
       "         'police': 1,\n",
       "         'expect': 1,\n",
       "         'hit': 1,\n",
       "         'shall': 1,\n",
       "         'All': 1,\n",
       "         'above': 1,\n",
       "         'nature': 1,\n",
       "         'After': 1,\n",
       "         'feel': 1,\n",
       "         'Not': 1,\n",
       "         'view': 1,\n",
       "         'return': 1,\n",
       "         'various': 1,\n",
       "         'merely': 1,\n",
       "         '50': 1,\n",
       "         'paper': 1,\n",
       "         'trying': 1,\n",
       "         'treatment': 1,\n",
       "         'age': 1,\n",
       "         'wrote': 1,\n",
       "         'states': 1,\n",
       "         'matter': 1,\n",
       "         'seem': 1,\n",
       "         'job': 1,\n",
       "         'data': 1,\n",
       "         'free': 1,\n",
       "         'Of': 1,\n",
       "         'development': 1,\n",
       "         'ideas': 1,\n",
       "         'remember': 1,\n",
       "         'worked': 1,\n",
       "         'continued': 1,\n",
       "         'difficult': 1,\n",
       "         'Washington': 1,\n",
       "         'play': 1,\n",
       "         '6': 1,\n",
       "         'equipment': 1,\n",
       "         'anything': 1,\n",
       "         'medical': 1,\n",
       "         'sat': 1,\n",
       "         'try': 1,\n",
       "         'met': 1,\n",
       "         'value': 1,\n",
       "         'rest': 1,\n",
       "         'trade': 1,\n",
       "         'stage': 1,\n",
       "         'pattern': 1,\n",
       "         'mother': 1,\n",
       "         'gave': 1,\n",
       "         'necessary': 1,\n",
       "         'force': 1,\n",
       "         'St.': 1,\n",
       "         'leave': 1,\n",
       "         'patient': 1,\n",
       "         'required': 1,\n",
       "         'plant': 1,\n",
       "         'degree': 1,\n",
       "         'conditions': 1,\n",
       "         '12': 1,\n",
       "         'A.': 1,\n",
       "         'hands': 1,\n",
       "         'reported': 1,\n",
       "         'live': 1,\n",
       "         'Union': 1,\n",
       "         'arms': 1,\n",
       "         '5': 1,\n",
       "         'period': 1,\n",
       "         'students': 1,\n",
       "         'plan': 1,\n",
       "         'center': 1,\n",
       "         'instead': 1,\n",
       "         'talk': 1,\n",
       "         'kept': 1,\n",
       "         'received': 1,\n",
       "         'literature': 1,\n",
       "         'simple': 1,\n",
       "         'town': 1,\n",
       "         'therefore': 1,\n",
       "         'forces': 1,\n",
       "         'simply': 1,\n",
       "         '15': 1,\n",
       "         'wanted': 1,\n",
       "         'total': 1,\n",
       "         'changes': 1,\n",
       "         'However': 1,\n",
       "         '&': 1,\n",
       "         'moment': 1,\n",
       "         'fine': 1,\n",
       "         'wide': 1,\n",
       "         'personal': 1,\n",
       "         'kind': 1,\n",
       "         'taking': 1,\n",
       "         'million': 1,\n",
       "         'food': 1,\n",
       "         'control': 1,\n",
       "         'influence': 1,\n",
       "         'women': 1,\n",
       "         'population': 1,\n",
       "         'hours': 1,\n",
       "         'Government': 1,\n",
       "         'international': 1,\n",
       "         'Island': 1,\n",
       "         'basis': 1,\n",
       "         'situation': 1,\n",
       "         'society': 1,\n",
       "         'performance': 1,\n",
       "         'bad': 1,\n",
       "         'efforts': 1,\n",
       "         'brought': 1,\n",
       "         'individual': 1,\n",
       "         '1961': 1,\n",
       "         'ago': 1,\n",
       "         'meaning': 1,\n",
       "         'Since': 1,\n",
       "         'leaders': 1,\n",
       "         'Now': 1,\n",
       "         'Thus': 1,\n",
       "         'alone': 1,\n",
       "         'First': 1,\n",
       "         'gone': 1,\n",
       "         'effort': 1,\n",
       "         'feeling': 1,\n",
       "         'hard': 1,\n",
       "         'private': 1,\n",
       "         'purpose': 1,\n",
       "         'understand': 1,\n",
       "         'boys': 1,\n",
       "         'century': 1,\n",
       "         'final': 1,\n",
       "         'love': 1,\n",
       "         'air': 1,\n",
       "         'stand': 1,\n",
       "         'season': 1,\n",
       "         'distance': 1,\n",
       "         'law': 1,\n",
       "         'makes': 1,\n",
       "         '25': 1,\n",
       "         'girls': 1,\n",
       "         'care': 1,\n",
       "         'example': 1,\n",
       "         'experience': 1,\n",
       "         'gun': 1,\n",
       "         'America': 1,\n",
       "         'Miss': 1,\n",
       "         'War': 1,\n",
       "         'temperature': 1,\n",
       "         'Department': 1,\n",
       "         'special': 1,\n",
       "         'foreign': 1,\n",
       "         'using': 1,\n",
       "         'table': 1,\n",
       "         'step': 1,\n",
       "         'moved': 1,\n",
       "         'growth': 1,\n",
       "         'eight': 1,\n",
       "         'comes': 1,\n",
       "         'voice': 1,\n",
       "         'husband': 1,\n",
       "         'military': 1,\n",
       "         'meeting': 1,\n",
       "         'provide': 1,\n",
       "         'based': 1,\n",
       "         'needed': 1,\n",
       "         'audience': 1,\n",
       "         'easy': 1,\n",
       "         'idea': 1,\n",
       "         'increase': 1,\n",
       "         'ground': 1,\n",
       "         'beyond': 1,\n",
       "         'suddenly': 1,\n",
       "         'child': 1,\n",
       "         'steps': 1,\n",
       "         'name': 1,\n",
       "         'wall': 1,\n",
       "         'particularly': 1,\n",
       "         'firm': 1,\n",
       "         'study': 1,\n",
       "         '4': 1,\n",
       "         'From': 1,\n",
       "         'Although': 1,\n",
       "         'month': 1,\n",
       "         'ones': 1,\n",
       "         'likely': 1,\n",
       "         'cause': 1,\n",
       "         'due': 1,\n",
       "         'effect': 1,\n",
       "         'president': 1,\n",
       "         'pool': 1,\n",
       "         'months': 1,\n",
       "         'trial': 1,\n",
       "         'questions': 1,\n",
       "         'level': 1,\n",
       "         'served': 1,\n",
       "         'countries': 1,\n",
       "         'surface': 1,\n",
       "         'figure': 1,\n",
       "         'question': 1,\n",
       "         'probably': 1,\n",
       "         'Even': 1,\n",
       "         'So': 1,\n",
       "         'cities': 1,\n",
       "         'cost': 1,\n",
       "         'teeth': 1,\n",
       "         'throughout': 1,\n",
       "         'turn': 1,\n",
       "         'price': 1,\n",
       "         'game': 1,\n",
       "         'major': 1,\n",
       "         'Congress': 1,\n",
       "         'radio': 1,\n",
       "         'sometimes': 1,\n",
       "         'close': 1,\n",
       "         'weeks': 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_table = []\n",
    "\n",
    "for v in vocabs:\n",
    "    uw = word_count[v] / num_total_words\n",
    "    uw_alpha = int((uw ** 0.75) / z)\n",
    "    unigram_table.extend([v] * uw_alpha)\n",
    "    \n",
    "Counter(unigram_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model\n",
    "\n",
    "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index['<UNK>'], seq))\n",
    "    return torch.LongTensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    batch_size = targets.shape[0]\n",
    "    neg_samples = []\n",
    "    for i in range(batch_size):  #(1, k)\n",
    "        target_index = targets[i].item()\n",
    "        nsample      = []\n",
    "        while (len(nsample) < k):\n",
    "            neg = random.choice(unigram_table)\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).reshape(1, -1))\n",
    "        \n",
    "    return torch.cat(neg_samples) #batch_size, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "x, y = random_batch(batch_size, corpus)\n",
    "x_tensor = torch.LongTensor(x)\n",
    "y_tensor = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "neg_samples = negative_sampling(y_tensor, unigram_table, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32060])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16223, 18431, 39234, 30927, 41503])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_samples[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipgramNeg(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(SkipgramNeg, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "        self.logsigmoid        = nn.LogSigmoid()\n",
    "    \n",
    "    def forward(self, center, outside, negative):\n",
    "        #center, outside:  (bs, 1)\n",
    "        #negative       :  (bs, k)\n",
    "        \n",
    "        center_embed   = self.embedding_center(center) #(bs, 1, emb_size)\n",
    "        outside_embed  = self.embedding_outside(outside) #(bs, 1, emb_size)\n",
    "        negative_embed = self.embedding_outside(negative) #(bs, k, emb_size)\n",
    "        \n",
    "        uovc           = outside_embed.bmm(center_embed.transpose(1, 2)).squeeze(2) #(bs, 1)\n",
    "        ukvc           = -negative_embed.bmm(center_embed.transpose(1, 2)).squeeze(2) #(bs, k)\n",
    "        ukvc_sum       = torch.sum(ukvc, 1).reshape(-1, 1) #(bs, 1)\n",
    "        \n",
    "        loss           = self.logsigmoid(uovc) + self.logsigmoid(ukvc_sum)\n",
    "        \n",
    "        return -torch.mean(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test your model\n",
    "emb_size = 2\n",
    "voc_size = len(vocabs)\n",
    "model = SkipgramNeg(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(x_tensor, y_tensor, neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3903, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_epoch(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss: 2.045120 | Time: 2m 55s\n",
      "Epoch: 20 | Loss: 2.193151 | Time: 5m 50s\n",
      "Epoch: 30 | Loss: 5.670602 | Time: 8m 42s\n",
      "Epoch: 40 | Loss: 8.271481 | Time: 11m 36s\n",
      "Epoch: 50 | Loss: 1.074299 | Time: 14m 28s\n",
      "Epoch: 60 | Loss: 3.020118 | Time: 17m 19s\n",
      "Epoch: 70 | Loss: 2.535974 | Time: 20m 11s\n",
      "Epoch: 80 | Loss: 6.078465 | Time: 23m 4s\n",
      "Epoch: 90 | Loss: 1.404506 | Time: 25m 56s\n",
      "Epoch: 100 | Loss: 3.428915 | Time: 28m 46s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "num_epochs = 100\n",
    "window_size = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #get batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus, window_size)\n",
    "    input_tensor = torch.LongTensor(input_batch)\n",
    "    label_tensor = torch.LongTensor(label_batch)\n",
    "    \n",
    "    #predict\n",
    "    neg_samples = negative_sampling(label_tensor, unigram_table, k)\n",
    "    loss = model(input_tensor, label_tensor, neg_samples)\n",
    "    \n",
    "    #backprogate\n",
    "    optimizer.zero_grad()                                                                                                 \n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    # Log epoch time\n",
    "    epoch_mins, epoch_secs = log_epoch(start, time.time())\n",
    "    #print the loss\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | Loss: {loss:.6f} | Time: {epoch_mins}m {epoch_secs}s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plot the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Spectra',\n",
       " 'Result',\n",
       " 'speaks',\n",
       " 'Worth',\n",
       " 'Porgy',\n",
       " 'equate',\n",
       " 'suffered',\n",
       " 'eyeball',\n",
       " 'led',\n",
       " 'spring',\n",
       " 'appealing',\n",
       " 'saucepan',\n",
       " 'industries',\n",
       " 'Andy',\n",
       " 'elevates',\n",
       " 'reverie',\n",
       " 'tendon',\n",
       " 'commemorates',\n",
       " 'Igbo',\n",
       " 'genesis',\n",
       " 'Mist',\n",
       " 'Reub',\n",
       " 'Stetson',\n",
       " 'unmixed',\n",
       " 'fuels',\n",
       " 'd-c',\n",
       " 'qualms',\n",
       " 'electromagnetic',\n",
       " 'nominating',\n",
       " 'Response',\n",
       " 'timers',\n",
       " 'Steinberg',\n",
       " 'begin',\n",
       " 'Clement',\n",
       " 'skips',\n",
       " 'retrieve',\n",
       " 'existing',\n",
       " 'firmer',\n",
       " 'dismay',\n",
       " 'Tsar',\n",
       " 'voted',\n",
       " 'pocketbook',\n",
       " 'Revolutionary',\n",
       " 'awash',\n",
       " 'derrick',\n",
       " 'curdling',\n",
       " 'confronted',\n",
       " 'evocative',\n",
       " 'weatherstrip',\n",
       " 'indexing',\n",
       " 'subcontracting',\n",
       " 'crosses',\n",
       " 'all-purpose',\n",
       " 'reckon',\n",
       " 'anionic',\n",
       " 'delicious',\n",
       " 'Octet',\n",
       " 'Antietam',\n",
       " 'chairs',\n",
       " 'settle',\n",
       " 'Pettersson',\n",
       " 'humane',\n",
       " 'Swallow-Barn',\n",
       " 'outpouring',\n",
       " 'Extensions',\n",
       " 'symmetry',\n",
       " 'Revolution',\n",
       " 'thirty-three',\n",
       " 'Sears',\n",
       " 'Lionel',\n",
       " 'farce',\n",
       " 'give',\n",
       " 'Lockheed',\n",
       " 'Brassbound',\n",
       " 'transience',\n",
       " 'Atomic',\n",
       " 'inevitability',\n",
       " 'hearest',\n",
       " 'discord',\n",
       " 'folk-music',\n",
       " 'Jenks',\n",
       " 'Lot',\n",
       " 'rightness',\n",
       " 'critters',\n",
       " 'laboratory',\n",
       " 'locker',\n",
       " 'acording',\n",
       " 'Gill',\n",
       " 'tall-growing',\n",
       " 'bemoans',\n",
       " 'shield',\n",
       " 'transducer',\n",
       " 'Slough',\n",
       " 'calves',\n",
       " 'despairingly',\n",
       " 'secession',\n",
       " 'Ullman',\n",
       " 'pedimented',\n",
       " 'Glowering',\n",
       " 'second-echelon',\n",
       " 'snake',\n",
       " 'Vermejo',\n",
       " 'acclaims',\n",
       " 'navigate',\n",
       " 'Kings',\n",
       " 'monkeys',\n",
       " 'Somay',\n",
       " 'Appropriations',\n",
       " 'epiphysis',\n",
       " 'teen-ager',\n",
       " 'Beautiful',\n",
       " 'halo',\n",
       " 'Hampshire',\n",
       " '102285000',\n",
       " 'Grapefruit',\n",
       " 'playful',\n",
       " '04.2',\n",
       " 'discoveries',\n",
       " 'Aristotelian',\n",
       " 'antiphonal',\n",
       " 'Native',\n",
       " 'letterman',\n",
       " 'cruising',\n",
       " 'Microscopic',\n",
       " 'originals',\n",
       " 'Retired',\n",
       " 'were',\n",
       " 'Tucson',\n",
       " '1850',\n",
       " 'hostesses',\n",
       " 'malformations',\n",
       " '1921',\n",
       " 'chugging',\n",
       " 'aspen',\n",
       " 'Riggs',\n",
       " 'Aurelius',\n",
       " 'manager',\n",
       " 'Diet',\n",
       " 'floods',\n",
       " 'teamsters',\n",
       " 'Pisces',\n",
       " 'set',\n",
       " 'Seeming',\n",
       " 'strongest',\n",
       " 'Mutants',\n",
       " 'Minnett',\n",
       " 'Afranio',\n",
       " 'asserting',\n",
       " 'abnormal',\n",
       " 'eagerly',\n",
       " 'babbiting',\n",
       " 'whether',\n",
       " 'calumny',\n",
       " 'tending',\n",
       " 'Belmont',\n",
       " 'damed',\n",
       " 'Horton',\n",
       " 'interrupt',\n",
       " 'hedonism',\n",
       " 'Carpenter',\n",
       " 'corniest',\n",
       " 'salamander',\n",
       " 'recognizes',\n",
       " 'Indeed',\n",
       " 'gleaming',\n",
       " 'end',\n",
       " 'Seventeenth',\n",
       " 'undoubtedly',\n",
       " 'Yesterday',\n",
       " 'basso',\n",
       " 'scimitar',\n",
       " 'arteriolosclerosis',\n",
       " 'stone-blind',\n",
       " 'decorum',\n",
       " 'soon',\n",
       " 'Tojos',\n",
       " 'rationalism',\n",
       " 'ciliated',\n",
       " 'two-part',\n",
       " 'dreamin',\n",
       " 'beer-cooling',\n",
       " 'Prix',\n",
       " 'stationmaster',\n",
       " 'censorship',\n",
       " 'Ky.',\n",
       " 'urine',\n",
       " 'idiocies',\n",
       " 'dismayed',\n",
       " 'Triandos',\n",
       " 'bureaucracy',\n",
       " 'Walt',\n",
       " 'week-long',\n",
       " 'headsman',\n",
       " 'fiscal',\n",
       " 'intervals',\n",
       " 'importance',\n",
       " 'haint',\n",
       " 'charge-a-plate',\n",
       " 'resignation',\n",
       " 'corrugated',\n",
       " 'mint',\n",
       " 'regularly',\n",
       " 'Front',\n",
       " 'gliders',\n",
       " 'universally',\n",
       " 'clients',\n",
       " 'posterity',\n",
       " 'propriety',\n",
       " 'Diving',\n",
       " 'fair-looking',\n",
       " 'sluggers',\n",
       " 'dots',\n",
       " 'bulk',\n",
       " 'Gannett',\n",
       " 'rot',\n",
       " 'Pardon',\n",
       " 'healing',\n",
       " 'residential',\n",
       " 'proper',\n",
       " 'checkbook',\n",
       " 'Jap',\n",
       " 'Trumbull',\n",
       " 'ruddy',\n",
       " 'Ironically',\n",
       " 'hard-to-get',\n",
       " 'divider',\n",
       " 'setup',\n",
       " 'disarming',\n",
       " 'castigation',\n",
       " 'Popular',\n",
       " 'aber',\n",
       " 'Natalie',\n",
       " 'Sitting',\n",
       " 'elevator',\n",
       " 'Sunset',\n",
       " 'stolen',\n",
       " 'Charlotte',\n",
       " 'Colorama',\n",
       " 'Hartweger',\n",
       " 'bowed',\n",
       " 'Prison',\n",
       " 'attacked',\n",
       " 'stitched',\n",
       " 'Physicians',\n",
       " 'halftime',\n",
       " 'marriage',\n",
       " 'amongst',\n",
       " 'specialization',\n",
       " 'Platonic',\n",
       " 'linguists',\n",
       " 'self-interest',\n",
       " 'exhaling',\n",
       " 'then',\n",
       " 'deputy',\n",
       " '1846',\n",
       " 'exploitation',\n",
       " 'Policemen',\n",
       " 'submerged',\n",
       " 'Presbyterian',\n",
       " 'Records',\n",
       " 'official',\n",
       " 'beckoned',\n",
       " 'worshiping',\n",
       " 'hugh',\n",
       " 'hens',\n",
       " 'psychologists',\n",
       " 'expedient',\n",
       " 'sarcastic',\n",
       " 'Axis',\n",
       " 'Hemphill',\n",
       " 'speculate',\n",
       " 'natural',\n",
       " '172400',\n",
       " 'regulative',\n",
       " 'instruct',\n",
       " '1911',\n",
       " 'Eighteenth',\n",
       " 'unashamedly',\n",
       " 'hummocks',\n",
       " 'battlefield',\n",
       " 'golly',\n",
       " 'McKenzie',\n",
       " 'opening-day',\n",
       " 'adventurous',\n",
       " 'Hallowell',\n",
       " 'mycology',\n",
       " 'jure',\n",
       " 'unequalled',\n",
       " 'Munich',\n",
       " 'Editor',\n",
       " 'shopkeepers',\n",
       " 'fille',\n",
       " 'Gigenza',\n",
       " 'evidencing',\n",
       " 'Eire',\n",
       " 'millennium',\n",
       " 'articulated',\n",
       " 'gorging',\n",
       " 'unquestionably',\n",
       " 'Behan',\n",
       " 'chemist',\n",
       " 'Following',\n",
       " 'rattler',\n",
       " 'jitters',\n",
       " 'freshly',\n",
       " 'bluster',\n",
       " 'Same',\n",
       " 'Ambushes',\n",
       " 'location',\n",
       " 'directrices',\n",
       " 'other',\n",
       " 'invoke',\n",
       " 'movingly',\n",
       " 'thence',\n",
       " 'burlesque',\n",
       " 'wobbled',\n",
       " 'waning',\n",
       " 'whizzed',\n",
       " 'Gurion',\n",
       " 'detonated',\n",
       " 'Bevel',\n",
       " 'sexton',\n",
       " 'Fitzgerald',\n",
       " 'DeHaviland',\n",
       " 'anti-American',\n",
       " 'Representing',\n",
       " 'allow',\n",
       " 'Royaux',\n",
       " 'rudeness',\n",
       " '02',\n",
       " 'asks',\n",
       " 'aim',\n",
       " 'linoleum',\n",
       " 'Commander-in-Chief',\n",
       " 'lost',\n",
       " '1957',\n",
       " 'gesture',\n",
       " 'trades',\n",
       " 'malaise',\n",
       " 'doghouse',\n",
       " 'Shall',\n",
       " 'overindulged',\n",
       " '8280',\n",
       " 'pantheist',\n",
       " 'Deutsche',\n",
       " 'occluded',\n",
       " 'honeymoon',\n",
       " 'Maynor',\n",
       " 'atrociously',\n",
       " 'tribunals',\n",
       " 'pursed',\n",
       " 'Interstate',\n",
       " 'blossomed',\n",
       " 'echoed',\n",
       " 'sustenance',\n",
       " 'employers',\n",
       " 'slacks',\n",
       " '1769',\n",
       " 'swung',\n",
       " 'graceful',\n",
       " '725',\n",
       " 'supplanting',\n",
       " 'naked',\n",
       " 'nilpotent',\n",
       " 'depart',\n",
       " 'Billy',\n",
       " 'Lorena',\n",
       " 'Beirut',\n",
       " 'double-breasted',\n",
       " 'rosy',\n",
       " 'legally',\n",
       " 'serviceable',\n",
       " 'Lois',\n",
       " 'optional',\n",
       " 'antiquated',\n",
       " 'Length',\n",
       " 'Pohly',\n",
       " 'incarnation',\n",
       " 'forma',\n",
       " 'Placing',\n",
       " 'indirect',\n",
       " 'kamikaze',\n",
       " 'confessed',\n",
       " 'reinforced',\n",
       " 'Sailing',\n",
       " 'pardonable',\n",
       " 'assist',\n",
       " 'Warsaw',\n",
       " 'sheered',\n",
       " 'Chopin',\n",
       " 'Guard',\n",
       " 'ecumenicists',\n",
       " 'Afro-Asian',\n",
       " 'Grabski',\n",
       " 'licked',\n",
       " 'impersonal',\n",
       " 'forswears',\n",
       " 'hunted',\n",
       " 'Nevada',\n",
       " 'classifications',\n",
       " 'Beatrice',\n",
       " 'speech',\n",
       " 'understated',\n",
       " 'Push-Pull',\n",
       " 'coconut',\n",
       " 'hopscotch',\n",
       " 'Dimes',\n",
       " 'Pornsen',\n",
       " 'Sunday',\n",
       " 'ex-fighter',\n",
       " 'centennial',\n",
       " 'scheme',\n",
       " 'Adcock',\n",
       " '97',\n",
       " 'surprises',\n",
       " 'Burnes',\n",
       " 'Knoll',\n",
       " 'inspect',\n",
       " '.028',\n",
       " 'dishonesty',\n",
       " 'corrupts',\n",
       " 'Territories',\n",
       " 'Plunking',\n",
       " 'bearings',\n",
       " 'alight',\n",
       " 'significant',\n",
       " 'precocity',\n",
       " 'Snapped',\n",
       " 'Ruger',\n",
       " 'satirist',\n",
       " 'Morrison',\n",
       " 'Yehudi',\n",
       " 'betrays',\n",
       " 'Honshu',\n",
       " 'forest',\n",
       " 'Catskills',\n",
       " 'Seventeen',\n",
       " 'half-turned',\n",
       " 'Sides',\n",
       " 'scrap',\n",
       " 'layer',\n",
       " 'typewriters',\n",
       " 'Aye-yah-ah-ah',\n",
       " 'penalties',\n",
       " 'De',\n",
       " 'straightaway',\n",
       " 'Passage',\n",
       " 'Wister',\n",
       " 'colon',\n",
       " 'despatched',\n",
       " 'processing',\n",
       " 'Severna',\n",
       " 'See',\n",
       " 'WBAI',\n",
       " 'explosives',\n",
       " 'portfolio',\n",
       " 'fares',\n",
       " 'oats',\n",
       " 'ramification',\n",
       " 'blitzes',\n",
       " 'replacing',\n",
       " 'monitoring',\n",
       " 'Pemberton',\n",
       " 'transversely',\n",
       " 'concessionaire',\n",
       " 'tailgate',\n",
       " 'pickup',\n",
       " 'encephalographic',\n",
       " 'Professionally',\n",
       " 'Daly',\n",
       " 'enacting',\n",
       " 'sledding',\n",
       " 'Citizen',\n",
       " 'undersecretary',\n",
       " 'Lay',\n",
       " 'Rondo',\n",
       " 'awfully',\n",
       " 'cards',\n",
       " 'truths',\n",
       " '11744',\n",
       " 'Dung',\n",
       " 'knotted',\n",
       " 'estranged',\n",
       " 'McLish',\n",
       " 'prohibited',\n",
       " 'mustiness',\n",
       " 'winking',\n",
       " 'vocalic',\n",
       " 'funnier',\n",
       " 'monograph',\n",
       " 'meats',\n",
       " 'Huntingtons',\n",
       " 'urging',\n",
       " 'reclassified',\n",
       " 'conveniently',\n",
       " 'marshalled',\n",
       " 'pre-war',\n",
       " 'resultant',\n",
       " 'Dilys',\n",
       " 'Conference',\n",
       " 'appointee',\n",
       " 'humanity',\n",
       " 'snows',\n",
       " 'Machines',\n",
       " 'Roman',\n",
       " 'self-preservation',\n",
       " 'incalculable',\n",
       " 'exaggerate',\n",
       " 'catechism',\n",
       " 'prose',\n",
       " 'booklet',\n",
       " 'therapeutic',\n",
       " 'redeemed',\n",
       " 'Parti',\n",
       " 'wisely',\n",
       " 'brightest',\n",
       " 'electrotherapist',\n",
       " 'arcus',\n",
       " 'tournaments',\n",
       " 'conjoined',\n",
       " 'prudentially',\n",
       " 'kisses',\n",
       " 'scrutin',\n",
       " 'Elena',\n",
       " 'inversely',\n",
       " 'uprooted',\n",
       " 'commentators',\n",
       " 'yearnings',\n",
       " 'threes',\n",
       " 'Worcestershire',\n",
       " 'Bustard',\n",
       " 'Karol',\n",
       " 'recipient',\n",
       " 'mid-fifties',\n",
       " 'Bartol',\n",
       " 'family-oriented',\n",
       " 'admirers',\n",
       " 'grasp',\n",
       " 'inning',\n",
       " 'bend',\n",
       " 'unendurable',\n",
       " 'facility',\n",
       " 'warmly',\n",
       " 'Thirties',\n",
       " 'self-critical',\n",
       " 'point',\n",
       " 'lui',\n",
       " 'glides',\n",
       " 'identifications',\n",
       " 'impotence',\n",
       " 'hard-to-please',\n",
       " 'bureau',\n",
       " 'Lower',\n",
       " 'civil',\n",
       " 'stone-still',\n",
       " 'Kodyke',\n",
       " 'trigonal',\n",
       " 'obliterating',\n",
       " 'East',\n",
       " 'Platter',\n",
       " 'Considerable',\n",
       " 'hiss',\n",
       " 'birdbath',\n",
       " 'nab',\n",
       " 'passes',\n",
       " 'letting',\n",
       " 'synchronize',\n",
       " 'Rosemary',\n",
       " 'Hunter',\n",
       " 'bhoy',\n",
       " 'broad',\n",
       " 'Jahr',\n",
       " 'mounting',\n",
       " 'yesteryear',\n",
       " 'blinked',\n",
       " 'overeat',\n",
       " 'hedge',\n",
       " 'adjusting',\n",
       " 'grandmothers',\n",
       " 'Community',\n",
       " 'Romano',\n",
       " 'argue',\n",
       " 'Treatment',\n",
       " 'Cares',\n",
       " 'garishness',\n",
       " 'firepower',\n",
       " 'presides',\n",
       " 'foreseeing',\n",
       " 'trichloroacetic',\n",
       " 'cargo',\n",
       " 'bronc',\n",
       " 'Romaniuk',\n",
       " 'Adame',\n",
       " 'good-looking',\n",
       " 'ein',\n",
       " 'doctor',\n",
       " 'Testament',\n",
       " 'Felske',\n",
       " 'nobody',\n",
       " 'lunge',\n",
       " 'Semra',\n",
       " 'planer',\n",
       " 'Directionality',\n",
       " 'shortcuts',\n",
       " 'rough',\n",
       " 'slapping',\n",
       " 'Branch',\n",
       " 'Fleisher',\n",
       " 'Prose',\n",
       " 'eleventh',\n",
       " 'indenture',\n",
       " 'leadership',\n",
       " 'performer',\n",
       " 'Reduced',\n",
       " 'storyline',\n",
       " 'violate',\n",
       " 'Ed',\n",
       " 'rally',\n",
       " 'mentioning',\n",
       " 'Mayer',\n",
       " 'enterprise',\n",
       " 'Security',\n",
       " 'reached',\n",
       " 'monde',\n",
       " 'pathologist',\n",
       " 'Helping',\n",
       " 'Acey',\n",
       " 'didn',\n",
       " 'rotor',\n",
       " 'transitions',\n",
       " 'Reps.',\n",
       " 'flashing',\n",
       " '1886',\n",
       " 'Haqvin',\n",
       " 'Robbery',\n",
       " 'Kleiber',\n",
       " 'Sokol',\n",
       " 'Booby',\n",
       " 'nests',\n",
       " 'arable',\n",
       " 'powder',\n",
       " 'Torah',\n",
       " 'sprays',\n",
       " 'prefaced',\n",
       " 'Rickards',\n",
       " 'detractor',\n",
       " 'interrelations',\n",
       " 'Prohibition',\n",
       " 'confide',\n",
       " 'Athabascan',\n",
       " 'Rig-Veda',\n",
       " 'Wonderland',\n",
       " 'humans',\n",
       " 'Dietetic',\n",
       " 'straighten',\n",
       " 'Satellites',\n",
       " 'investigated',\n",
       " 'painstakingly',\n",
       " 'forty-fifth',\n",
       " 'Drive-in',\n",
       " 'stretching',\n",
       " 'embankment',\n",
       " 'protests',\n",
       " 'grammar',\n",
       " 'transformation',\n",
       " 'Weider',\n",
       " 'miscalculated',\n",
       " 'adorn',\n",
       " 'Calmer',\n",
       " 'yeah',\n",
       " 'foreboding',\n",
       " 'Colt',\n",
       " 'Quakeress',\n",
       " 'Cinemactor',\n",
       " 'Comique',\n",
       " 'convicted',\n",
       " 'detachable',\n",
       " 'Auxiliaries',\n",
       " 'vermilion',\n",
       " 'involve',\n",
       " 'drifts',\n",
       " 'overexcited',\n",
       " 'Pompadour',\n",
       " 'rhythmic',\n",
       " 'affectionate',\n",
       " 'nip',\n",
       " 'desiring',\n",
       " 'Farnese',\n",
       " 'Bruhn',\n",
       " 'slights',\n",
       " 'Stephanie',\n",
       " 'insulted',\n",
       " 'Rameau',\n",
       " 'Cleanth',\n",
       " 'out-reaching',\n",
       " 'Tolley',\n",
       " 'Thay',\n",
       " 'reserpine',\n",
       " 'pulp',\n",
       " 'names',\n",
       " 'Simplex',\n",
       " 'landslide',\n",
       " 'souvenirs',\n",
       " 'cuisine',\n",
       " 'uptown',\n",
       " 'beginners',\n",
       " 'Packard',\n",
       " 'printing',\n",
       " 'expands',\n",
       " 'terry',\n",
       " 'discrepancy',\n",
       " 'consequences',\n",
       " 'migrant',\n",
       " 'recoil',\n",
       " 'war',\n",
       " 'nailed',\n",
       " 'locations',\n",
       " 'shin',\n",
       " 'stirring',\n",
       " 'Goodwin',\n",
       " 'proclaiming',\n",
       " 'rancor',\n",
       " 'picturing',\n",
       " 'accordion',\n",
       " 'ventilated',\n",
       " 'blandly',\n",
       " 'resent',\n",
       " 'occipital',\n",
       " 'knuckles',\n",
       " 'story',\n",
       " 'reddish',\n",
       " 'outdrew',\n",
       " 'charging',\n",
       " 'consideration',\n",
       " 'Dimensions',\n",
       " 'inglorious',\n",
       " 'vocals',\n",
       " 'SS.',\n",
       " 'Ziegfeld',\n",
       " 'crush',\n",
       " 'draining',\n",
       " 'output',\n",
       " 'LSO',\n",
       " 'Pinscher',\n",
       " 'arch',\n",
       " 'O.K.',\n",
       " 'Gennaro',\n",
       " 'exacerbation',\n",
       " 'extended',\n",
       " 'munching',\n",
       " 'forsaken',\n",
       " 'bureaucratic',\n",
       " 'toffee',\n",
       " 'Doubtful',\n",
       " 'sobbingly',\n",
       " 'ABO',\n",
       " 'decorating',\n",
       " 'mouthed',\n",
       " 'boxcar',\n",
       " 'circa',\n",
       " 'Astor',\n",
       " 'Breakfast',\n",
       " 'falling',\n",
       " 'path',\n",
       " 'dental',\n",
       " 'gluttons',\n",
       " 'stoop',\n",
       " 'strenuously',\n",
       " 'quaint',\n",
       " 'enough',\n",
       " 'Soviet',\n",
       " 'Frans',\n",
       " 'echo',\n",
       " 'creepy',\n",
       " 'Love',\n",
       " 'recriminations',\n",
       " '320',\n",
       " 'maneuverability',\n",
       " 'Skill',\n",
       " 'regulation',\n",
       " 'Hatfield',\n",
       " 'lubrication',\n",
       " 'Tougas',\n",
       " 'milk',\n",
       " 'literatures',\n",
       " 'Crosson',\n",
       " 'Province',\n",
       " 'flame',\n",
       " 'remanded',\n",
       " 'melodies',\n",
       " 'Promoters',\n",
       " 'readjust',\n",
       " 'Uh',\n",
       " 'Someone',\n",
       " 'unawareness',\n",
       " 'mystics',\n",
       " 'blanket',\n",
       " 'Greyhound',\n",
       " 'Sullam',\n",
       " 'pervaded',\n",
       " 'participated',\n",
       " 'addle-brained',\n",
       " 'announcement',\n",
       " 'Richmond-Petersburg',\n",
       " 'Paray',\n",
       " 'crying',\n",
       " 'Wisman',\n",
       " 'Sussex',\n",
       " '11',\n",
       " 'foil',\n",
       " 'specialize',\n",
       " 'engender',\n",
       " 'democracy',\n",
       " 'Mecholyl',\n",
       " 'Butlers',\n",
       " 'rarity',\n",
       " 'savory',\n",
       " 'redefinition',\n",
       " 'Blend',\n",
       " 'whereof',\n",
       " 'plummeting',\n",
       " 'unfriendly',\n",
       " 'Lippman',\n",
       " 'Court-packing',\n",
       " 'chamber',\n",
       " 'defiantly',\n",
       " 'Distally',\n",
       " 'half-heartedly',\n",
       " 'unilaterally',\n",
       " 'corral',\n",
       " 'dodge',\n",
       " 'fine-looking',\n",
       " 'subfigures',\n",
       " 'Buaford',\n",
       " 'detract',\n",
       " 'Co-operative',\n",
       " 'inside',\n",
       " 'one-story',\n",
       " 'Jacinto',\n",
       " 'Rachel',\n",
       " 'aspect',\n",
       " 'Caracas',\n",
       " 'verses',\n",
       " 'Brothers',\n",
       " 'decimal',\n",
       " 'beachhead',\n",
       " 'Landis',\n",
       " 'coincide',\n",
       " 'headroom',\n",
       " 'standing',\n",
       " 'phthalate',\n",
       " 'hells',\n",
       " 'prevision',\n",
       " 'consuming',\n",
       " 'vintage',\n",
       " 'Centredale',\n",
       " 'non-profit',\n",
       " 'forefathers',\n",
       " 'twenty-three',\n",
       " 'Doe',\n",
       " 'Subgroups',\n",
       " 'princes',\n",
       " 'cowboy',\n",
       " 'ill-prepared',\n",
       " 'done',\n",
       " 'Elected',\n",
       " 'punctually',\n",
       " 'siren',\n",
       " 'whiskered',\n",
       " 'disjointed',\n",
       " 'effluents',\n",
       " 'butt',\n",
       " 'lever-action',\n",
       " '19th',\n",
       " 'Alden',\n",
       " 'provokes',\n",
       " 'poets',\n",
       " 'inspire',\n",
       " 'kerosene',\n",
       " 'vibrato',\n",
       " '0.7',\n",
       " 'silver',\n",
       " 'undergirding',\n",
       " 'mis-reading',\n",
       " 'passages',\n",
       " 'breakables',\n",
       " 'gallstone',\n",
       " 'practiced',\n",
       " 'buss',\n",
       " 'pedestrian',\n",
       " 'idiomatic',\n",
       " 'disapproves',\n",
       " 'Forever',\n",
       " 'Thornburg',\n",
       " 'quadrillion',\n",
       " 'hog',\n",
       " 'Internal',\n",
       " 'cracking',\n",
       " 'accord',\n",
       " 'Windsor',\n",
       " 'fill',\n",
       " 'student',\n",
       " 'strong-made',\n",
       " 'occur',\n",
       " 'disappointing',\n",
       " 'mushrooming',\n",
       " 'Poetry',\n",
       " 'sportsmen',\n",
       " 'drowsed',\n",
       " 'undressing',\n",
       " 'spill',\n",
       " 'triangular',\n",
       " 'Melcher',\n",
       " 'group',\n",
       " 'adorable',\n",
       " 'workings',\n",
       " 'swiftness',\n",
       " 'obsequious',\n",
       " 'Cotter',\n",
       " 'spurring',\n",
       " 'mark',\n",
       " 'flaunting',\n",
       " 'outline',\n",
       " 'Sickness',\n",
       " 'demonstrators',\n",
       " 'Shabbat',\n",
       " 'Superior',\n",
       " 'remotely',\n",
       " 'retire',\n",
       " 'downtown',\n",
       " 'measured',\n",
       " 'Tchaikovsky',\n",
       " 'realigning',\n",
       " 'take',\n",
       " 'integrated',\n",
       " '2.5',\n",
       " 'hatted',\n",
       " 'Rusk',\n",
       " 'Suspicion',\n",
       " 'Whether',\n",
       " 'respiratory',\n",
       " 'bottled',\n",
       " 'glottochronological',\n",
       " 'mortality',\n",
       " 'eliminations',\n",
       " 'usage',\n",
       " 'retirements',\n",
       " 'squinting',\n",
       " 'pike',\n",
       " 'dining-room',\n",
       " 'heathenish',\n",
       " 'swaggering',\n",
       " 'co-operating',\n",
       " 'Delaware',\n",
       " 'eliminate',\n",
       " 'Bashir',\n",
       " 'beguiling',\n",
       " 'septic',\n",
       " 'haughtily',\n",
       " 'Masons',\n",
       " 'anti-intellectual',\n",
       " 'S-s-sahjunt',\n",
       " 'outfielders',\n",
       " 'millennia',\n",
       " 'Ambrose',\n",
       " 'bar',\n",
       " 'motive',\n",
       " 'Co.',\n",
       " 'extraterrestrial',\n",
       " 'bother',\n",
       " 'insulated',\n",
       " 'Admiralty',\n",
       " 'Amos',\n",
       " 'Korneyev',\n",
       " 'brink',\n",
       " 'gloomily',\n",
       " 'Mexico',\n",
       " 'Pharmical',\n",
       " 'unpleasantness',\n",
       " 'Assessors',\n",
       " 'shovels',\n",
       " 'intuitively',\n",
       " 'poor',\n",
       " 'Shreveport',\n",
       " 'fanciful',\n",
       " 'kidney',\n",
       " 'item',\n",
       " 'Looky',\n",
       " 'Dog',\n",
       " 'cures',\n",
       " 'Phone',\n",
       " 'blue',\n",
       " 'postures',\n",
       " 'pithy',\n",
       " 'grandparents',\n",
       " 'involution',\n",
       " 'bomb-proof',\n",
       " 'Camden',\n",
       " 'burrowed',\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34310])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana = torch.LongTensor([word2index['banana']])\n",
    "banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4911, 0.0580]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana_embed_c = model.embedding_center(banana)\n",
    "banana_embed_o = model.embedding_outside(banana)\n",
    "banana_embed   = (banana_embed_c + banana_embed_o) / 2\n",
    "banana_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6124, -0.3962]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana_embed_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "        \n",
    "    word = torch.LongTensor([word2index[word]])\n",
    "    \n",
    "    embed_c = model.embedding_center(word)\n",
    "    embed_o = model.embedding_outside(word)\n",
    "    embed   = (embed_c + embed_o) / 2\n",
    "    \n",
    "    return embed[0][0].item(), embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4316416084766388, -0.3188936412334442)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('fruit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.155967116355896, -0.2509961724281311)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7880674600601196, 0.03841546177864075)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4910973310470581, 0.057979583740234375)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('banana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4910973310470581, 0.057979583740234375)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana = get_embed('banana')\n",
    "banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4316416084766388, -0.3188936412334442)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit = get_embed('fruit')\n",
    "fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.155967116355896, -0.2509961724281311)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = get_embed('cat')\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06204238097571135"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(banana) @ np.array(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4245669978095941\n",
      "0.729088556850849\n"
     ]
    }
   ],
   "source": [
    "#more formally is to divide by its norm\n",
    "def cosine_similarity(A, B):\n",
    "    dot_product = np.dot(A, B)\n",
    "    norm_a = np.linalg.norm(A)\n",
    "    norm_b = np.linalg.norm(B)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity\n",
    "\n",
    "print(cosine_similarity(np.array(banana), np.array(cat)))\n",
    "print(cosine_similarity(np.array(banana), np.array(fruit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'skipgram_negSampling_model.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export word2index and index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(word2index, open('skipgram_negSampling_word2index.pkl', 'wb'))\n",
    "pickle.dump(index2word, open('skipgram_negSampling_index2word.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
