{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name : Suryansh Srivastava\n",
    "# ID   : 124997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report at the end of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "# importing classes for the respective models\n",
    "from models.skipgram import Skipgram\n",
    "from models.skipgram_negSampling import SkipgramNeg\n",
    "from models.glove import Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle files\n",
    "def load(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models name and path\n",
    "\n",
    "models = {\n",
    "    \"Skipgram\": \"./models/skipgram_model.pkl\",\n",
    "    \"SkipgramNEG\": \"./models/skipgram_negSampling_model.pkl\",\n",
    "    \"Glove\": \"./models/glove_model.pkl\",\n",
    "    \"GloveGensim\": \"./models/glove_gensim_model.pkl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index2word name and path for the respective models\n",
    "index2word={\n",
    "    \"Skipgram\": \"./models/skipgram_index2word.pkl\",\n",
    "    \"SkipgramNEG\": \"./models/skipgram_negSampling_index2word.pkl\",\n",
    "    \"Glove\": \"./models/glove_index2word.pkl\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2index name and path for the respective models\n",
    "word2index={\n",
    "    \"Skipgram\": \"./models/skipgram_word2index.pkl\",\n",
    "    \"SkipgramNEG\": \"./models/skipgram_negSampling_word2index.pkl\",\n",
    "    \"Glove\": \"./models/glove_word2index.pkl\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "loaded_models = {name: load(path) for name, path in models.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index2word\n",
    "loaded_index2word = {name: load(path) for name, path in index2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word2index\n",
    "loaded_word2index = {name: load(path) for name, path in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word analogy dataset url\n",
    "wordAnalogy_url = \"https://www.fit.vutbr.cz/~imikolov/rnnlm/word-test.v1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# syntactic \n",
    "def fetch_data_syntactic_analogy(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    lines = response.text.strip().split('\\n')\n",
    "    \n",
    "    # Extract specific section\n",
    "    section_start = ': gram7-past-tense'\n",
    "    section_end = ': gram8-plural'\n",
    "    extract_lines = []\n",
    "    in_section = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(section_start):\n",
    "            in_section = True\n",
    "            continue\n",
    "        elif line.startswith(section_end):\n",
    "            break\n",
    "\n",
    "        if in_section:\n",
    "            extract_lines.append(line)\n",
    "\n",
    "    return [line.split() for line in extract_lines if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic\n",
    "def fetch_data_semantic_analogy(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    lines = response.text.strip().split('\\n')\n",
    "    \n",
    "    # Extract specific section\n",
    "    section_start = ': capital-common-countries'\n",
    "    section_end = ': currency'\n",
    "    extract_lines = []\n",
    "    in_section = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(section_start):\n",
    "            in_section = True\n",
    "            continue\n",
    "        elif line.startswith(section_end):\n",
    "            break\n",
    "\n",
    "        if in_section:\n",
    "            extract_lines.append(line)\n",
    "\n",
    "    return [line.split() for line in extract_lines if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_analogy_data = fetch_data_syntactic_analogy(wordAnalogy_url)\n",
    "semantic_analogy_data = fetch_data_semantic_analogy(wordAnalogy_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_analogy(model_name,word_a, word_b, word_c, embeddings=None, word_to_idx=None, idx_to_word=None):\n",
    "    if(model_name == \"GloveGensim\"):\n",
    "        result = loaded_models['GloveGensim'].most_similar(positive=[word_c, word_b], negative=[word_a])\n",
    "        return result[0][0]\n",
    "\n",
    "    try:\n",
    "        vec_a = embeddings[word_to_idx[word_a]]\n",
    "        vec_b = embeddings[word_to_idx[word_b]]\n",
    "        vec_c = embeddings[word_to_idx[word_c]]\n",
    "        target_vec = vec_b - vec_a + vec_c\n",
    "\n",
    "        similarities = torch.matmul(embeddings, target_vec) / (\n",
    "            torch.norm(embeddings, dim=1) * torch.norm(target_vec) + 1e-8\n",
    "        )\n",
    "        best_match_idx = torch.argmax(similarities).item()\n",
    "        return idx_to_word[best_match_idx]\n",
    "    except KeyError as e:\n",
    "        return None  # Return None if any word is not in the vocabulary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_accuracy(model_name,analogy_data, embeddings=None, word_to_idx=None, idx_to_word=None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for question in analogy_data:\n",
    "        if len(question) != 4:\n",
    "            continue\n",
    "        word_a, word_b, word_c, word_d = question\n",
    "        predicted_word=None\n",
    "        if(model_name == \"GloveGensim\"):\n",
    "            try:\n",
    "                predicted_word = predict_analogy(model_name,word_a, word_b, word_c)\n",
    "            except:\n",
    "                predicted_word = None\n",
    "        else:\n",
    "            predicted_word = predict_analogy(model_name,word_a, word_b, word_c, embeddings, word_to_idx, idx_to_word)\n",
    "\n",
    "        if predicted_word == word_d:\n",
    "            correct += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntactic_accuracy(model_name,analogy_data, embeddings=None, word_to_idx=None, idx_to_word=None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for question in analogy_data:\n",
    "        if len(question) != 4:\n",
    "            continue\n",
    "        word_a, word_b, word_c, word_d = question\n",
    "        # Process syntactic relationships directly from the dataset\n",
    "        if word_a.endswith(\"ing\") or word_a.endswith(\"ed\"):\n",
    "            predicted_word=None\n",
    "            if(model_name == \"GloveGensim\"):\n",
    "                try:\n",
    "                    predicted_word = predict_analogy(model_name,word_a, word_b, word_c)\n",
    "                except:\n",
    "                    predicted_word = None\n",
    "            else:\n",
    "                predicted_word = predict_analogy(model_name,word_a, word_b, word_c, embeddings, word_to_idx, idx_to_word)\n",
    "\n",
    "            if predicted_word == word_d:\n",
    "                correct += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "    syntactic_accuracy = correct / total if total > 0 else 0\n",
    "    return syntactic_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipgram Model\n",
      "Syntactic Accuracy: 0.00%\n",
      "Semantic Accuracy: 0.00%\n",
      "\n",
      "\n",
      "SkipgramNEG Model\n",
      "Syntactic Accuracy: 0.00%\n",
      "Semantic Accuracy: 0.00%\n",
      "\n",
      "\n",
      "Glove Model\n",
      "Syntactic Accuracy: 0.00%\n",
      "Semantic Accuracy: 0.00%\n",
      "\n",
      "\n",
      "GloveGensim Model\n",
      "Syntactic Accuracy: 0.32%\n",
      "Semantic Accuracy: 0.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in loaded_models.items():\n",
    "    syntactic_acc = None\n",
    "    semantic_acc = None\n",
    "    if(model_name == \"GloveGensim\"):\n",
    "        syntactic_acc = syntactic_accuracy(model_name,syntactic_analogy_data)\n",
    "        semantic_acc = semantic_accuracy(model_name,semantic_analogy_data)\n",
    "    else:\n",
    "            \n",
    "        if(model_name == \"Glove\"):\n",
    "            center_embeddings = model.center_embedding.weight.data\n",
    "            outside_embeddings = model.outside_embedding.weight.data\n",
    "        else:\n",
    "            center_embeddings = model.embedding_center.weight.data\n",
    "            outside_embeddings = model.embedding_outside.weight.data\n",
    "        \n",
    "        word_to_idx = loaded_word2index[model_name]\n",
    "        idx_to_word = loaded_index2word[model_name]\n",
    "\n",
    "        syntactic_acc = syntactic_accuracy(model_name,syntactic_analogy_data, center_embeddings, word_to_idx, idx_to_word)\n",
    "        semantic_acc = semantic_accuracy(model_name,semantic_analogy_data, center_embeddings, word_to_idx, idx_to_word)\n",
    "    \n",
    "    print(f\"{model_name} Model\")\n",
    "    print(f\"Syntactic Accuracy: {syntactic_acc * 100:.2f}%\")\n",
    "    print(f\"Semantic Accuracy: {semantic_acc * 100:.2f}%\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "with open('./dataset/wordsim_similarity_goldstandard.txt', 'r') as f:\n",
    "    content = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(model_name,word):\n",
    "    word2index = loaded_word2index[model_name]\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "        \n",
    "    word = torch.LongTensor([word2index[word]])\n",
    "    embed_c=None\n",
    "    embed_o=None\n",
    "    if(model_name == \"Glove\"):\n",
    "        embed_c = loaded_models[model_name].center_embedding(word)\n",
    "        embed_o = loaded_models[model_name].outside_embedding(word) \n",
    "    else:\n",
    "        embed_c = loaded_models[model_name].embedding_center(word)\n",
    "        embed_o = loaded_models[model_name].embedding_outside(word)\n",
    "    embed   = (embed_c + embed_o) / 2\n",
    "    \n",
    "    return embed[0][0].item(), embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dot_product(A, B):\n",
    "    dot_product = np.dot(A, B)\n",
    "    return dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipgram Model\n",
      "SignificanceResult(statistic=-0.08945283790183964, pvalue=0.20437601213430073)\n",
      "32.53141376806432\n",
      "\n",
      "\n",
      "SkipgramNEG Model\n",
      "SignificanceResult(statistic=-0.09749908646575546, pvalue=0.16639849187449327)\n",
      "33.057867528332956\n",
      "\n",
      "\n",
      "Glove Model\n",
      "SignificanceResult(statistic=-0.053119810535583206, pvalue=0.4516309214048949)\n",
      "33.43038299665055\n",
      "\n",
      "\n",
      "GloveGensim Model\n",
      "SignificanceResult(statistic=-0.1061521629817607, pvalue=0.13171888783314104)\n",
      "28.534438082743094\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"Skipgram\",\"SkipgramNEG\",\"Glove\",\"GloveGensim\"]\n",
    "for model_name in model_names:\n",
    "    similarity = []\n",
    "    for line in lines:\n",
    "        word1 = line[0]\n",
    "        word2 = line[1]\n",
    "        score = float(line[2])\n",
    "\n",
    "        try:\n",
    "            if(model_name == \"GloveGensim\"):\n",
    "                similarity.append(get_dot_product(model.get_vector(word1), model.get_vector(word2)))\n",
    "            else:\n",
    "                similarity.append(get_dot_product(get_embed(model_name,word1), get_embed(model_name,word2)))\n",
    "        except:\n",
    "            similarity.append(0.0)\n",
    "\n",
    "    print(f\"{model_name} Model\")\n",
    "    # find the Spearman Correlation\n",
    "    spearman_correlation = spearmanr(similarity, [line[2] for line in lines])\n",
    "    print(spearman_correlation)\n",
    "\n",
    "    # find the MSE\n",
    "    squared_error = [(similarity[i] - float(lines[i][2]))**2 for i in range(len(similarity))]\n",
    "    mse = sum(squared_error) / len(similarity)\n",
    "    print(mse)\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While executing the above code for Glove Gensim model, the Kernel crashed multiple times. Mostly it crashed and only twice the syntactic and semantic accuracy were calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Compare Skip-gram, Skip-gram negative sampling, GloVe models on training loss, training time. \n",
    "### 2. Use Word analogies dataset to calucalte between syntactic and semantic accuracy, similar to the methods in the Word2Vec and GloVe paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the four notebooks i.e. 01 - Word2Vec (Skipgram).ipynb, 02 - Word2Vec (Neg Sampling).ipynb, 03 - GloVe from Scratch.ipynb and 04 - GloVe (Gensim).ipynb which are used to train their respective models, we observe the training loss and training time for each model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model            | Window Size | Training Loss | Training time | Syntactic Accuracy | Semantic Accuracy |\n",
    "|-----------------|-------------|--------------|---------------|--------------------|-------------------|\n",
    "| Skipgram       |      5      |  13.209658   |    28m 36s    |        0%          |         0%        |\n",
    "| Skipgram (NEG) |      5      |   3.428915   |    28m 46s    |        0%          |         0%        |\n",
    "| Glove          |      5      |   0.431736   |      0m 0s    |        0%          |         0%        |\n",
    "| Glove (Gensim) |      5      |      -       |       -       |        0.32%      |         0%    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use the similarity dataset4 to find the correlation between your modelsâ€™ dot product and the provided similarity metrics. (from scipy.stats import spearmanr) Assess if your embeddings correlate with human judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|Model|Skipgram|NEG|GloVe|GloVe (gensim)|Y_True|\n",
    "|-----|--------|---|-----|----------------------|------|\n",
    "|MSE|32.5314|33.0578|33.4303|28.5344|1.0000|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
